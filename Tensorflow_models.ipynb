{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mo-NUuZmKInC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "## Progress bar\n",
        "from tqdm.auto import tqdm\n",
        "import pylab as plt\n",
        "import copy\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, callbacks, regularizers\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y86ViYIFKN9j",
        "outputId": "71f72f1e-b733-4719-edad-a98251d7c4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All ok -- code is running on a Google Colab\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  print(\"All ok -- code is running on a Google Colab\")\n",
        "else:\n",
        "    print(\"===\"*15, \" WARNING \",\"===\"*15)\n",
        "    print(\"For DSA4212 assignment 1, code needs to be run on a Google Colab with a single GPU\")\n",
        "    print(\"===\"*15, \" WARNING \",\"===\"*15)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c7FvOu7KPeB",
        "outputId": "347eecfc-f726-4465-b63c-182ba09f8b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnUFqD2nKRQf",
        "outputId": "9f1fd4ec-cd9a-4c21-abe8-fcf1e960db7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/DSA4212/assignment_1_script\n"
          ]
        }
      ],
      "source": [
        "# goto to data folder -- you may need to change this location\n",
        "%cd /content/drive/MyDrive/DSA4212/assignment_1_script/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJfvFRD5K6ub",
        "outputId": "9a719dc1-04d9-40d5-a4cf-8111912c1024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Img Shape: 128x128x3\n"
          ]
        }
      ],
      "source": [
        "class_names=[\"fish\", \"dog\", \"device\", \"chainsaw\", \"church\", \"horn\", \"truck\", \"petrol\", \"golf\", \"parachute\"]\n",
        "\n",
        "# load data -- be patient, does take a few secs\n",
        "data_train_all = np.load(\"assignment_1_train.npz\")\n",
        "data_test = np.load(\"assignment_1_test.npz\")\n",
        "\n",
        "X_train_all = data_train_all[\"img\"].astype(np.float32) / 255.   # set pixel intensities to [0,1]\n",
        "X_test = data_test[\"img\"].astype(np.float32) / 255.\n",
        "Y_train_all = data_train_all[\"label\"].astype(int)\n",
        "Y_test = data_test[\"label\"].astype(int)\n",
        "\n",
        "_,H,W,C = X_train_all.shape\n",
        "print(f\"Img Shape: {H}x{W}x{C}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2y4MrGLpK8Y7"
      },
      "outputs": [],
      "source": [
        "# shuffle the train set\n",
        "indices_shuffled = np.arange(len(X_train_all))\n",
        "np.random.shuffle(indices_shuffled)\n",
        "X_train_all = X_train_all[indices_shuffled]\n",
        "Y_train_all = Y_train_all[indices_shuffled]\n",
        "\n",
        "# shuffle the validation set\n",
        "indices_shuffled = np.arange(len(X_test))\n",
        "np.random.shuffle(indices_shuffled)\n",
        "X_test = X_test[indices_shuffled]\n",
        "Y_test = Y_test[indices_shuffled]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pyaFjbNsqxUm"
      },
      "outputs": [],
      "source": [
        "len_train_all = len(X_train_all)\n",
        "len_train = int(0.8 * len_train_all)\n",
        "len_val = len_train_all - len_train\n",
        "len_tets = len(X_test)\n",
        "\n",
        "X_train = X_train_all[:len_train]\n",
        "Y_train = Y_train_all[:len_train]\n",
        "\n",
        "X_val = X_train_all[len_train:]\n",
        "Y_val = Y_train_all[len_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAfENDnreyn-",
        "outputId": "76f15b22-8280-4922-f7ab-42d52a1c479b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7436, 128, 128, 3)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Un-augmented training images with batch size = 32\n",
        "default_gen = keras.preprocessing.image.ImageDataGenerator().flow(\n",
        "    X_train, Y_train,\n",
        "    batch_size=32)\n",
        "\n",
        "# Un-augmented validation images with batch size = 32\n",
        "val_generator = keras.preprocessing.image.ImageDataGenerator().flow(\n",
        "    X_val, Y_val,\n",
        "    batch_size=32)\n",
        "\n",
        "# Image augmentation; feeds the images into this generator which augments it\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Augmented training images with batch size = 32\n",
        "train_generator = train_datagen.flow(\n",
        "    X_train, Y_train,\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmJO5BelSwf_",
        "outputId": "1049207b-ac64-4507-8133-3390ba353934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "233/233 [==============================] - 6s 18ms/step - loss: 2.0680 - accuracy: 0.2600\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 4s 18ms/step - loss: 1.6182 - accuracy: 0.4566\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 1.3049 - accuracy: 0.5666\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 4s 18ms/step - loss: 1.0360 - accuracy: 0.6607\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 4s 18ms/step - loss: 0.7294 - accuracy: 0.7562\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.5180 - accuracy: 0.8253\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 4s 18ms/step - loss: 0.3711 - accuracy: 0.8778\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 4s 18ms/step - loss: 0.2761 - accuracy: 0.9072\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 4s 19ms/step - loss: 0.2133 - accuracy: 0.9264\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 4s 19ms/step - loss: 0.1781 - accuracy: 0.9411\n",
            "59/59 - 1s - loss: 2.5113 - accuracy: 0.5914 - 590ms/epoch - 10ms/step\n",
            "\n",
            "Test accuracy: 59.139782190322876 %\n"
          ]
        }
      ],
      "source": [
        "# Basic CNN model\n",
        "BCCN = models.Sequential()\n",
        "BCCN.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "BCCN.add(layers.Flatten())\n",
        "BCCN.add(layers.Dense(64, activation='relu'))\n",
        "BCCN.add(layers.Dropout(0.2))\n",
        "BCCN.add(layers.Dense(10,activation = \"softmax\"))\n",
        "\n",
        "BCCN.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BCCN.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "test_loss, test_acc = BCCN.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxeUvr_iGcpc"
      },
      "outputs": [],
      "source": [
        "# Base LeNet model\n",
        "BLN = models.Sequential()\n",
        "BLN.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
        "BLN.add(layers.AveragePooling2D((2,2)))\n",
        "BLN.add(layers.Activation('sigmoid'))\n",
        "BLN.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "BLN.add(layers.AveragePooling2D((2,2)))\n",
        "BLN.add(layers.Activation('sigmoid'))\n",
        "BLN.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
        "BLN.add(layers.Flatten())\n",
        "BLN.add(layers.Dense(84, activation='relu'))\n",
        "BLN.add(layers.Dense(10))\n",
        "\n",
        "\n",
        "BLN.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BLN.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "test_loss, test_acc = BLN.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w50UAoTRRKx5"
      },
      "outputs": [],
      "source": [
        "# Base AlexNet\n",
        "AlexNet = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), activation='relu', input_shape=(128,128,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "AlexNet.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "AlexNet.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "test_loss, test_acc = AlexNet.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRgpb0tvT98n"
      },
      "outputs": [],
      "source": [
        "## VGG 16\n",
        "\n",
        "features = [64,128]\n",
        "VGG=keras.models.Sequential()\n",
        "\n",
        "VGG.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "#pooling layer\n",
        "VGG.add(layers.MaxPooling2D(2,2))\n",
        "VGG.add(layers.BatchNormalization()) \n",
        "for i in features:\n",
        "\n",
        "#covolution layer\n",
        "  VGG.add(layers.Conv2D(i,(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "  VGG.add(layers.MaxPooling2D(2,2))\n",
        "  VGG.add(layers.BatchNormalization())\n",
        "\n",
        "VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "VGG.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "#covolution layer\n",
        "#VGG.add(layers.Conv2D(features[1],(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "#VGG.add(layers.MaxPooling2D(2,2))\n",
        "#VGG.add(layers.BatchNormalization())\n",
        "#covolution layer\n",
        "#VGG.add(layers.Conv2D(features[2],(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "#VGG.add(layers.MaxPooling2D(2,2))\n",
        "#VGG.add(layers.BatchNormalization())\n",
        "#covolution layer\n",
        "#VGG.add(layers.Conv2D(features[3],(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "#VGG.add(layers.MaxPooling2D(2,2))\n",
        "#VGG.add(layers.BatchNormalization())\n",
        "#i/p layer\n",
        "#VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "#VGG.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "opt = keras.optimizers.Adamax(learning_rate=0.0001)\n",
        "\n",
        "VGG.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#VGG.summary()\n",
        "VGG.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "val_loss, val_acc = VGG.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T5lBzwiGveR"
      },
      "source": [
        "## Initialisation stage ##\n",
        "\n",
        "- Will be using the VGG architecture as a reference\n",
        "- Constant learning rate of 0.001\n",
        "- Adam as optimiser\n",
        "- 3 layers for now with features, [32,48,64]\n",
        "- Activation function will be sigmoid\n",
        "\n",
        "\n",
        "These initial model settings are from the settings that yielded the highest validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "gfSMLzriHZ_f",
        "outputId": "cce6cbbb-3b93-4317-db3c-188acc403858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 39/233 [====>.........................] - ETA: 3:28 - loss: 3.2792 - accuracy: 0.2452"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e5c3e0848f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#VGG.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mVGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## VGG 16\n",
        "\n",
        "features = [48,64]\n",
        "VGG=keras.models.Sequential()\n",
        "\n",
        "VGG.add(layers.Conv2D(32,(3,3),activation='sigmoid',input_shape=(128,128,3)))\n",
        "#pooling layer\n",
        "VGG.add(layers.MaxPooling2D(2,2))\n",
        "VGG.add(layers.BatchNormalization()) \n",
        "for i in features:\n",
        "\n",
        "#covolution layer\n",
        "  VGG.add(layers.Conv2D(i,(3,3),activation='sigmoid'))\n",
        "#pooling layer\n",
        "  VGG.add(layers.MaxPooling2D(2,2))\n",
        "  VGG.add(layers.BatchNormalization())\n",
        "\n",
        "VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "VGG.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "VGG.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#VGG.summary()\n",
        "VGG.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "val_loss, val_acc = VGG.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfg_xSHfKx6c"
      },
      "source": [
        "## Overfit ##\n",
        "- Play around with the parameters to maximise training accuracy and at the same time increase validation accuracy.\n",
        "- Overfitted model specifications\n",
        "1. Activation function: Relu\n",
        "2. Kernel size : (3,3)\n",
        "3. Features : [32,48,64,128]\n",
        "4. Optimiser: Adam\n",
        "5. Lr_schedule : Exponential \n",
        "6. Initial LR : 0.0001\n",
        "\n",
        "- Training accuracy by 10th epoch : 0.9833\n",
        "- Validation accuracy : 0.6339\n",
        "- Training time: 1m 32s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9_cf0hgK48X",
        "outputId": "0eb74fe1-b711-4cfb-d01b-b31dcbe0381a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "233/233 [==============================] - 17s 20ms/step - loss: 1.6029 - accuracy: 0.4852\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 1.0711 - accuracy: 0.6555\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.8401 - accuracy: 0.7281\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.6581 - accuracy: 0.7883\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 0.4907 - accuracy: 0.8433\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.3293 - accuracy: 0.9024\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.2050 - accuracy: 0.9465\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 0.1408 - accuracy: 0.9630\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.0931 - accuracy: 0.9770\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.0686 - accuracy: 0.9833\n",
            "59/59 - 1s - loss: 1.5540 - accuracy: 0.6339 - 1s/epoch - 19ms/step\n",
            "\n",
            "Test accuracy: 63.38709592819214 %\n"
          ]
        }
      ],
      "source": [
        "## VGG 16\n",
        "# Changed optimiser to adam :57%\n",
        "# Changed max_pooling window (3,3):54%\n",
        "# Changed activation function to relu: 59%\n",
        "# Change features to [32,48,64,128]: 63%\n",
        "# Change to a changing learning rate: 65.91%\n",
        "# Change kernel size to (4,4): 63.9%\n",
        "# Change kernel size to (2,2): 65.69%\n",
        "# Adding one more dense layer: 64.999%\n",
        "\n",
        "\n",
        "features = [48,64,128,156]\n",
        "VGG=keras.models.Sequential()\n",
        "\n",
        "VGG.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "#pooling layer\n",
        "VGG.add(layers.MaxPooling2D(2,2))\n",
        "VGG.add(layers.BatchNormalization()) \n",
        "for i in features:\n",
        "\n",
        "#covolution layer\n",
        "  VGG.add(layers.Conv2D(i,(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "  VGG.add(layers.MaxPooling2D(2,2))\n",
        "  VGG.add(layers.BatchNormalization())\n",
        "\n",
        "VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "VGG.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "VGG.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#VGG.summary()\n",
        "VGG.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "val_loss, val_acc = VGG.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEFge5FPY9sW"
      },
      "source": [
        "## Regularization ##\n",
        "- Implementing restrictions and reducing capacity to increase validation accuracy at the expense of training accuracy\n",
        "- Dereasing batch size\n",
        "- Add dropout layer to each iteration\n",
        "- Add dropout layer in input stage\n",
        "- Early stopping\n",
        "- L2 and L1 regularisation\n",
        "\n",
        "Final model specifications\n",
        "1. Dropout layer at input stage (0.25)\n",
        "2. L2 regularisation at final dense layer (0.01)\n",
        "3. Early stopping (patience = 5, min_delta = 0.1)\n",
        "4. No batch size specification\n",
        "\n",
        "- Training accuracy by 10th epoch : 0.9627 (A lot of room to take increase validation accuracy)\n",
        "- Training time : 1m28s\n",
        "- Validation accuracy: 68.226%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "dKBIDpGMZLOX",
        "outputId": "b7399612-ffd8-40f4-d287-73ddc6d509d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "145/233 [=================>............] - ETA: 1:40 - loss: 1.8178 - accuracy: 0.4256"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e6554eb66200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#VGG.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mVGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## VGG 16\n",
        "## Using dropout layer per iteration\n",
        "# Add dropout layer(0.5) at each iteration: 60.5%\n",
        "# Add dropout layer(0.1) at each iteration: 67.688%\n",
        "# Add dropout layer(0.2) at each iteration: 69.95%\n",
        "# Add dropout layer(0.3) at each iteration: 68.33%\n",
        "# Add dropout layer(0.25) at each iteration: 71.77% , training accuracy: 0.757\n",
        "\n",
        "## Using dropout layer for first layer(0.25):68.27% , training accuracy: 0.9662\n",
        "\n",
        "## Decreasing batch size(Doesnt seem to do any good)\n",
        "# Batch_size 256 : 15%\n",
        "# Batch_size 750 : 13%  \n",
        "\n",
        "\n",
        "## Early stopping \n",
        "# Patience(5), min_delta(0.001) : 64.46% 56s\n",
        "# Patience(5), min_delta(0.01): 65.6989% 1m30s\n",
        "# Patience(5), min_delta(0.1): 65.86% 57s\n",
        "\n",
        "## L2 regularisation --> Will use this for grid search later\n",
        "# (0.001) 67.58%\n",
        "\n",
        "## L1 regularisation --> Will use this for grid search later\n",
        "# (0.001) 67.15%\n",
        "\n",
        "\n",
        "features = [48,64,128,156]\n",
        "VGG=keras.models.Sequential()\n",
        "\n",
        "VGG.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "#pooling layer\n",
        "VGG.add(layers.MaxPooling2D(2,2))\n",
        "VGG.add(layers.BatchNormalization()) \n",
        "VGG.add(layers.Dropout(0.25))\n",
        "for i in features:\n",
        "\n",
        "#covolution layer\n",
        "  VGG.add(layers.Conv2D(i,(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "  VGG.add(layers.MaxPooling2D(2,2))\n",
        "  VGG.add(layers.BatchNormalization())\n",
        "#  VGG.add(layers.Dropout(0.25))\n",
        "\n",
        "VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "VGG.add(layers.Dense(10,activation='softmax',kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.1, # minimium amount of change to count as an improvement\n",
        "    patience=5, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "VGG.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#VGG.summary()\n",
        "VGG.fit(default_gen, validation_data = val_generator, epochs=10,callbacks=[early_stopping])\n",
        "\n",
        "val_loss, val_acc = VGG.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huCvMmF3nqVi"
      },
      "source": [
        "## Tuning parameters ##\n",
        "- The four hyperparameters that will require tuning will be min_delta, lambda and dropout rate.\n",
        "- This stage is about finding the best parameters that returns the best validation accuracy.\n",
        "\n",
        "1. Normal grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "1vAZEIXyosXp",
        "outputId": "2d56aca4-9493-4dfb-88a6-c5069562d703"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2c668b0830aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVGG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'VGG' is not defined"
          ]
        }
      ],
      "source": [
        "param_grid = dict(rate=[0.1,0.2,0.3,0.4,0.5],min_delta = [0.1,0.01,0.001,0.0001],l2 = [0.1,0.1,0.001,0.0001])\n",
        "grid = GridSearchCV(estimator=VGG, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw7VXgdzxKso"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
