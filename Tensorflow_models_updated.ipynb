{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo-NUuZmKInC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c627c7d-1d20-4fe7-f07b-0ad449e63551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m734.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "## Progress bar\n",
        "from tqdm.auto import tqdm\n",
        "import pylab as plt\n",
        "import copy\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, callbacks, regularizers\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "!pip install keras-tuner -q\n",
        "import keras_tuner\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y86ViYIFKN9j",
        "outputId": "8573e0d9-8c56-4a6e-c933-8e101b7d031f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All ok -- code is running on a Google Colab\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  print(\"All ok -- code is running on a Google Colab\")\n",
        "else:\n",
        "    print(\"===\"*15, \" WARNING \",\"===\"*15)\n",
        "    print(\"For DSA4212 assignment 1, code needs to be run on a Google Colab with a single GPU\")\n",
        "    print(\"===\"*15, \" WARNING \",\"===\"*15)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c7FvOu7KPeB",
        "outputId": "7b210062-8b13-4a9e-da0b-240cadd4bbc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnUFqD2nKRQf",
        "outputId": "75041cd1-3515-419d-ee00-1596307dabf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DSA4212/assignment_1\n"
          ]
        }
      ],
      "source": [
        "# goto to data folder -- you may need to change this location\n",
        "%cd /content/drive/MyDrive/DSA4212/assignment_1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJfvFRD5K6ub",
        "outputId": "86a3c52e-4dbc-49a0-d923-0f0a2db9e8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Img Shape: 128x128x3\n"
          ]
        }
      ],
      "source": [
        "class_names=[\"fish\", \"dog\", \"device\", \"chainsaw\", \"church\", \"horn\", \"truck\", \"petrol\", \"golf\", \"parachute\"]\n",
        "\n",
        "# load data -- be patient, does take a few secs\n",
        "data_train_all = np.load(\"assignment_1_train.npz\")\n",
        "data_test = np.load(\"assignment_1_test.npz\")\n",
        "\n",
        "X_train_all = data_train_all[\"img\"].astype(np.float32) / 255.   # set pixel intensities to [0,1]\n",
        "X_test = data_test[\"img\"].astype(np.float32) / 255.\n",
        "Y_train_all = data_train_all[\"label\"].astype(int)\n",
        "Y_test = data_test[\"label\"].astype(int)\n",
        "\n",
        "_,H,W,C = X_train_all.shape\n",
        "print(f\"Img Shape: {H}x{W}x{C}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y4MrGLpK8Y7"
      },
      "outputs": [],
      "source": [
        "# shuffle the train set\n",
        "indices_shuffled = np.arange(len(X_train_all))\n",
        "np.random.shuffle(indices_shuffled)\n",
        "X_train_all = X_train_all[indices_shuffled]\n",
        "Y_train_all = Y_train_all[indices_shuffled]\n",
        "\n",
        "# shuffle the validation set\n",
        "indices_shuffled = np.arange(len(X_test))\n",
        "np.random.shuffle(indices_shuffled)\n",
        "X_test = X_test[indices_shuffled]\n",
        "Y_test = Y_test[indices_shuffled]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyaFjbNsqxUm"
      },
      "outputs": [],
      "source": [
        "len_train_all = len(X_train_all)\n",
        "len_train = int(0.8 * len_train_all)\n",
        "len_val = len_train_all - len_train\n",
        "len_tets = len(X_test)\n",
        "\n",
        "X_train = X_train_all[:len_train]\n",
        "Y_train = Y_train_all[:len_train]\n",
        "\n",
        "X_val = X_train_all[len_train:]\n",
        "Y_val = Y_train_all[len_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAfENDnreyn-",
        "outputId": "76f15b22-8280-4922-f7ab-42d52a1c479b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7436, 128, 128, 3)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLxH6ZyUNC35"
      },
      "outputs": [],
      "source": [
        "# Un-augmented training images with batch size = 32\n",
        "default_gen = keras.preprocessing.image.ImageDataGenerator().flow(\n",
        "    X_train, Y_train,\n",
        "    batch_size=32)\n",
        "\n",
        "# Un-augmented validation images with batch size = 32\n",
        "val_generator = keras.preprocessing.image.ImageDataGenerator().flow(\n",
        "    X_val, Y_val,\n",
        "    batch_size=32)\n",
        "\n",
        "# Image augmentation; feeds the images into this generator which augments it\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split = 0.2)\n",
        "\n",
        "# Augmented training images with batch size = 32\n",
        "train_generator = train_datagen.flow(\n",
        "    X_train, Y_train,\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List of base models ##\n",
        " Testing out a few models inspired by architectures we will further develop\n",
        "1. Basic CNN model referencing lecture code. : 53.5% validation accuracy \n",
        "2. LeNet model : 9% validation accuracy\n",
        "3. AlexNet : 46% validation accuracy\n",
        "4. VGG16 : 59.6% validation accuracy\n",
        "\n",
        "Therefore, we will look into the VGG16 as well as the basic CNN model."
      ],
      "metadata": {
        "id": "6cCvoT8VDK46"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmJO5BelSwf_",
        "outputId": "fbe8bca0-4125-4882-8d40-0e13810258e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "233/233 [==============================] - 6s 21ms/step - loss: 1.8621 - accuracy: 0.3556 - val_loss: 1.6018 - val_accuracy: 0.4806\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 1.3662 - accuracy: 0.5465 - val_loss: 1.3653 - val_accuracy: 0.5597\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 1.0526 - accuracy: 0.6513 - val_loss: 1.2968 - val_accuracy: 0.5866\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.6909 - accuracy: 0.7730 - val_loss: 1.4040 - val_accuracy: 0.5839\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 0.3620 - accuracy: 0.8860 - val_loss: 1.8123 - val_accuracy: 0.5780\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.1638 - accuracy: 0.9520 - val_loss: 2.2380 - val_accuracy: 0.5672\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 6s 25ms/step - loss: 0.0768 - accuracy: 0.9789 - val_loss: 2.5845 - val_accuracy: 0.5473\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.0788 - accuracy: 0.9766 - val_loss: 2.8570 - val_accuracy: 0.5462\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.0613 - accuracy: 0.9822 - val_loss: 3.0722 - val_accuracy: 0.5366\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.0598 - accuracy: 0.9824 - val_loss: 3.3220 - val_accuracy: 0.5355\n",
            "59/59 - 0s - loss: 3.3220 - accuracy: 0.5355 - 462ms/epoch - 8ms/step\n",
            "\n",
            "Test accuracy: 53.54838967323303 %\n"
          ]
        }
      ],
      "source": [
        "#Basic CNN model\n",
        "BCCN = models.Sequential()\n",
        "BCCN.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.Conv2D(48, (3, 3), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "BCCN.add(layers.Flatten())\n",
        "BCCN.add(layers.Dense(128, activation='relu'))\n",
        "BCCN.add(layers.Dense(10,activation = \"softmax\"))\n",
        "\n",
        "BCCN.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BCCN.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "test_loss, test_acc = BCCN.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxeUvr_iGcpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e497a027-b01f-4bc7-8a30-90d6fc34ea69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "233/233 [==============================] - 8s 26ms/step - loss: 2.3953 - accuracy: 0.0968 - val_loss: 2.3024 - val_accuracy: 0.0919\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 2.3023 - accuracy: 0.1010 - val_loss: 2.3024 - val_accuracy: 0.0919\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 2.3022 - accuracy: 0.1014 - val_loss: 2.3022 - val_accuracy: 0.0919\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 2.3021 - accuracy: 0.0997 - val_loss: 2.3022 - val_accuracy: 0.0919\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 2.3022 - accuracy: 0.1021 - val_loss: 2.3023 - val_accuracy: 0.0919\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 6s 25ms/step - loss: 2.3021 - accuracy: 0.1002 - val_loss: 2.3022 - val_accuracy: 0.1075\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 2.3022 - accuracy: 0.1017 - val_loss: 2.3023 - val_accuracy: 0.1075\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 2.3022 - accuracy: 0.0984 - val_loss: 2.3023 - val_accuracy: 0.0919\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 6s 27ms/step - loss: 2.3022 - accuracy: 0.1023 - val_loss: 2.3023 - val_accuracy: 0.0919\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 2.3021 - accuracy: 0.1037 - val_loss: 2.3022 - val_accuracy: 0.0919\n",
            "59/59 - 0s - loss: 2.3022 - accuracy: 0.0919 - 467ms/epoch - 8ms/step\n",
            "\n",
            "Test accuracy: 9.193548560142517 %\n"
          ]
        }
      ],
      "source": [
        "# Base LeNet model\n",
        "BLN = models.Sequential()\n",
        "BLN.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
        "BLN.add(layers.AveragePooling2D((2,2)))\n",
        "BLN.add(layers.Activation('sigmoid'))\n",
        "BLN.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "BLN.add(layers.AveragePooling2D((2,2)))\n",
        "BLN.add(layers.Activation('sigmoid'))\n",
        "BLN.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
        "BLN.add(layers.Flatten())\n",
        "BLN.add(layers.Dense(84, activation='relu'))\n",
        "BLN.add(layers.Dense(10))\n",
        "\n",
        "\n",
        "BLN.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BLN.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "test_loss, test_acc = BLN.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w50UAoTRRKx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3197a7f-12c6-4113-dce1-bc003c82f845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "233/233 [==============================] - 11s 23ms/step - loss: 3.0672 - accuracy: 0.3081 - val_loss: 3.5479 - val_accuracy: 0.1285\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 6s 25ms/step - loss: 1.8019 - accuracy: 0.4207 - val_loss: 2.4059 - val_accuracy: 0.2468\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 1.6313 - accuracy: 0.4856 - val_loss: 2.3875 - val_accuracy: 0.2780\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 1.4678 - accuracy: 0.5424 - val_loss: 1.6294 - val_accuracy: 0.4769\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 1.4219 - accuracy: 0.5581 - val_loss: 3.6070 - val_accuracy: 0.2022\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 5s 21ms/step - loss: 1.3615 - accuracy: 0.5843 - val_loss: 2.0836 - val_accuracy: 0.3941\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 1.2649 - accuracy: 0.6120 - val_loss: 1.5504 - val_accuracy: 0.5435\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 5s 21ms/step - loss: 1.2089 - accuracy: 0.6302 - val_loss: 1.0995 - val_accuracy: 0.6505\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 1.1447 - accuracy: 0.6502 - val_loss: 1.6121 - val_accuracy: 0.4774\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 5s 21ms/step - loss: 1.1040 - accuracy: 0.6606 - val_loss: 1.7864 - val_accuracy: 0.4645\n",
            "59/59 - 0s - loss: 1.7864 - accuracy: 0.4645 - 407ms/epoch - 7ms/step\n",
            "\n",
            "Test accuracy: 46.45161330699921 %\n"
          ]
        }
      ],
      "source": [
        "# Base AlexNet\n",
        "AlexNet = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), activation='relu', input_shape=(128,128,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "AlexNet.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "AlexNet.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "test_loss, test_acc = AlexNet.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRgpb0tvT98n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62c501a-5a65-4e60-914a-ca66f22f66b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "233/233 [==============================] - 8s 23ms/step - loss: 1.9439 - accuracy: 0.3813 - val_loss: 3.0883 - val_accuracy: 0.0919\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 1.3683 - accuracy: 0.5542 - val_loss: 2.2467 - val_accuracy: 0.2677\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 1.1022 - accuracy: 0.6475 - val_loss: 1.4567 - val_accuracy: 0.5274\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 6s 25ms/step - loss: 0.9186 - accuracy: 0.7127 - val_loss: 1.3863 - val_accuracy: 0.5629\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.7691 - accuracy: 0.7669 - val_loss: 1.3478 - val_accuracy: 0.5758\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 0.6552 - accuracy: 0.8131 - val_loss: 1.3194 - val_accuracy: 0.5855\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.5626 - accuracy: 0.8429 - val_loss: 1.3182 - val_accuracy: 0.5962\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 0.4803 - accuracy: 0.8817 - val_loss: 1.3162 - val_accuracy: 0.6065\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 0.4053 - accuracy: 0.9081 - val_loss: 1.3226 - val_accuracy: 0.5995\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 6s 25ms/step - loss: 0.3434 - accuracy: 0.9263 - val_loss: 1.3307 - val_accuracy: 0.5968\n",
            "59/59 - 1s - loss: 1.3307 - accuracy: 0.5968 - 526ms/epoch - 9ms/step\n",
            "\n",
            "Test accuracy: 59.67742204666138 %\n"
          ]
        }
      ],
      "source": [
        "## VGG 16\n",
        "\n",
        "features = [64,128]\n",
        "VGG=keras.models.Sequential()\n",
        "\n",
        "VGG.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "#pooling layer\n",
        "VGG.add(layers.MaxPooling2D(2,2))\n",
        "VGG.add(layers.BatchNormalization()) \n",
        "for i in features:\n",
        "\n",
        "#covolution layer\n",
        "  VGG.add(layers.Conv2D(i,(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "  VGG.add(layers.MaxPooling2D(2,2))\n",
        "  VGG.add(layers.BatchNormalization())\n",
        "\n",
        "VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "VGG.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "#covolution layer\n",
        "#VGG.add(layers.Conv2D(features[1],(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "#VGG.add(layers.MaxPooling2D(2,2))\n",
        "#VGG.add(layers.BatchNormalization())\n",
        "#covolution layer\n",
        "#VGG.add(layers.Conv2D(features[2],(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "#VGG.add(layers.MaxPooling2D(2,2))\n",
        "#VGG.add(layers.BatchNormalization())\n",
        "#covolution layer\n",
        "#VGG.add(layers.Conv2D(features[3],(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "#VGG.add(layers.MaxPooling2D(2,2))\n",
        "#VGG.add(layers.BatchNormalization())\n",
        "#i/p layer\n",
        "#VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "#VGG.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "opt = keras.optimizers.Adamax(learning_rate=0.0001)\n",
        "\n",
        "VGG.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#VGG.summary()\n",
        "VGG.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "val_loss, val_acc = VGG.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16 model ##"
      ],
      "metadata": {
        "id": "NebSmYZbCVIy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T5lBzwiGveR"
      },
      "source": [
        "## Initialisation stage ##\n",
        "\n",
        "- Will be using the VGG architecture as a reference\n",
        "- Constant learning rate of 0.001\n",
        "- Adam as optimiser\n",
        "- 3 layers for now with features, [32,48,64]\n",
        "- Activation function will be sigmoid\n",
        "\n",
        "\n",
        "These initial model settings are from the settings that yielded the highest validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfSMLzriHZ_f",
        "outputId": "8929ee53-547b-44c6-ba4c-07324f41df66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "233/233 [==============================] - 8s 26ms/step - loss: 2.8388 - accuracy: 0.3519 - val_loss: 2.7576 - val_accuracy: 0.1091\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 1.8668 - accuracy: 0.5356 - val_loss: 2.6729 - val_accuracy: 0.3113\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 6s 25ms/step - loss: 1.0703 - accuracy: 0.6889 - val_loss: 2.3447 - val_accuracy: 0.4651\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 0.5603 - accuracy: 0.8209 - val_loss: 2.3714 - val_accuracy: 0.4758\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.3196 - accuracy: 0.8963 - val_loss: 2.1433 - val_accuracy: 0.5220\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.1607 - accuracy: 0.9516 - val_loss: 2.2027 - val_accuracy: 0.5301\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.0808 - accuracy: 0.9843 - val_loss: 2.1456 - val_accuracy: 0.5414\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 0.0402 - accuracy: 0.9948 - val_loss: 2.1756 - val_accuracy: 0.5392\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.0301 - accuracy: 0.9956 - val_loss: 2.1587 - val_accuracy: 0.5484\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 0.0140 - accuracy: 0.9995 - val_loss: 2.2397 - val_accuracy: 0.5468\n",
            "59/59 - 1s - loss: 2.2397 - accuracy: 0.5468 - 524ms/epoch - 9ms/step\n",
            "\n",
            "Test accuracy: 54.67742085456848 %\n"
          ]
        }
      ],
      "source": [
        "## VGG 16\n",
        "\n",
        "features = [48,64]\n",
        "VGG=keras.models.Sequential()\n",
        "\n",
        "VGG.add(layers.Conv2D(32,(3,3),activation='sigmoid',input_shape=(128,128,3)))\n",
        "#pooling layer\n",
        "VGG.add(layers.MaxPooling2D(2,2))\n",
        "VGG.add(layers.BatchNormalization()) \n",
        "for i in features:\n",
        "\n",
        "#covolution layer\n",
        "  VGG.add(layers.Conv2D(i,(3,3),activation='sigmoid'))\n",
        "#pooling layer\n",
        "  VGG.add(layers.MaxPooling2D(2,2))\n",
        "  VGG.add(layers.BatchNormalization())\n",
        "\n",
        "VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "VGG.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "VGG.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#VGG.summary()\n",
        "VGG.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "val_loss, val_acc = VGG.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfg_xSHfKx6c"
      },
      "source": [
        "## Overfit ##\n",
        "- Play around with the parameters to maximise training accuracy and at the same time increase validation accuracy.\n",
        "- Overfitted model specifications\n",
        "1. Activation function: Relu\n",
        "2. Kernel size : (3,3)\n",
        "3. Features : [32,48,64,128]\n",
        "4. Optimiser: Adam\n",
        "5. Lr_schedule : Exponential \n",
        "6. Initial LR : 0.0001\n",
        "\n",
        "- Training accuracy by 10th epoch : 0.9833\n",
        "- Validation accuracy : 0.6339\n",
        "- Training time: 1m 32s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9_cf0hgK48X",
        "outputId": "1b502a81-16ab-4556-85fa-c6e99572e60c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "233/233 [==============================] - 9s 27ms/step - loss: 1.5891 - accuracy: 0.4887 - val_loss: 3.5505 - val_accuracy: 0.0935\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 5s 21ms/step - loss: 1.0639 - accuracy: 0.6540 - val_loss: 1.8428 - val_accuracy: 0.4156\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 0.8176 - accuracy: 0.7290 - val_loss: 1.2584 - val_accuracy: 0.6097\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 0.6277 - accuracy: 0.8008 - val_loss: 1.2113 - val_accuracy: 0.6484\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 6s 25ms/step - loss: 0.4695 - accuracy: 0.8495 - val_loss: 1.1267 - val_accuracy: 0.6629\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.3329 - accuracy: 0.8979 - val_loss: 1.5032 - val_accuracy: 0.5839\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 6s 24ms/step - loss: 0.2022 - accuracy: 0.9434 - val_loss: 1.1912 - val_accuracy: 0.6753\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 0.1700 - accuracy: 0.9535 - val_loss: 1.2300 - val_accuracy: 0.6688\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 0.0825 - accuracy: 0.9824 - val_loss: 1.2547 - val_accuracy: 0.6672\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 6s 25ms/step - loss: 0.0717 - accuracy: 0.9829 - val_loss: 1.3644 - val_accuracy: 0.6672\n",
            "59/59 - 0s - loss: 1.3644 - accuracy: 0.6672 - 483ms/epoch - 8ms/step\n",
            "\n",
            "Test accuracy: 66.72043204307556 %\n"
          ]
        }
      ],
      "source": [
        "## VGG 16\n",
        "# Changed optimiser to adam :57%\n",
        "# Changed max_pooling window (3,3):54%\n",
        "# Changed activation function to relu: 59%\n",
        "# Change features to [32,48,64,128]: 63%\n",
        "# Change to a changing learning rate: 65.91%\n",
        "# Change kernel size to (4,4): 63.9%\n",
        "# Change kernel size to (2,2): 65.69%\n",
        "# Adding one more dense layer: 64.999%\n",
        "\n",
        "\n",
        "features = [48,64,128,156]\n",
        "VGG=keras.models.Sequential()\n",
        "\n",
        "VGG.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "#pooling layer\n",
        "VGG.add(layers.MaxPooling2D(2,2))\n",
        "VGG.add(layers.BatchNormalization()) \n",
        "for i in features:\n",
        "\n",
        "#covolution layer\n",
        "  VGG.add(layers.Conv2D(i,(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "  VGG.add(layers.MaxPooling2D(2,2))\n",
        "  VGG.add(layers.BatchNormalization())\n",
        "\n",
        "VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "VGG.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "VGG.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#VGG.summary()\n",
        "VGG.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "val_loss, val_acc = VGG.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEFge5FPY9sW"
      },
      "source": [
        "## Regularization ##\n",
        "- Implementing restrictions and reducing capacity to increase validation accuracy at the expense of training accuracy\n",
        "- Dereasing batch size\n",
        "- Add dropout layer to each iteration\n",
        "- Add dropout layer in input stage\n",
        "- Early stopping\n",
        "- L2 and L1 regularisation\n",
        "\n",
        "Final model specifications\n",
        "1. Dropout layer at input stage (0.25)\n",
        "2. L2 regularisation at final dense layer (0.01)\n",
        "3. Early stopping (patience = 5, min_delta = 0.1)\n",
        "4. No batch size specification\n",
        "\n",
        "- Training accuracy by 10th epoch : 0.9627 (A lot of room to take increase validation accuracy)\n",
        "- Training time : 1m28s\n",
        "- Validation accuracy: 68.226%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKBIDpGMZLOX",
        "outputId": "f560af30-74b1-4d10-eb36-8135219c83c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "233/233 [==============================] - 11s 33ms/step - loss: 1.6982 - accuracy: 0.4626 - val_loss: 3.2765 - val_accuracy: 0.0989\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 1.2038 - accuracy: 0.6131 - val_loss: 2.4651 - val_accuracy: 0.3274\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 8s 36ms/step - loss: 0.9622 - accuracy: 0.6884 - val_loss: 1.5978 - val_accuracy: 0.5328\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.7724 - accuracy: 0.7515 - val_loss: 1.7065 - val_accuracy: 0.5328\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.6339 - accuracy: 0.7987 - val_loss: 1.3333 - val_accuracy: 0.6059\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4977 - accuracy: 0.8471 - val_loss: 1.1768 - val_accuracy: 0.6554\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3628 - accuracy: 0.8956 - val_loss: 1.2650 - val_accuracy: 0.6586\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.2591 - accuracy: 0.9338 - val_loss: 1.2206 - val_accuracy: 0.6554\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.1907 - accuracy: 0.9576 - val_loss: 1.3321 - val_accuracy: 0.6640\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.1430 - accuracy: 0.9716 - val_loss: 1.3755 - val_accuracy: 0.6516\n",
            "59/59 - 1s - loss: 1.3755 - accuracy: 0.6516 - 547ms/epoch - 9ms/step\n",
            "\n",
            "Test accuracy: 65.16128778457642 %\n"
          ]
        }
      ],
      "source": [
        "## VGG 16\n",
        "## Using dropout layer per iteration\n",
        "# Add dropout layer(0.5) at each iteration: 60.5%\n",
        "# Add dropout layer(0.1) at each iteration: 67.688%\n",
        "# Add dropout layer(0.2) at each iteration: 69.95%\n",
        "# Add dropout layer(0.3) at each iteration: 68.33%\n",
        "# Add dropout layer(0.25) at each iteration: 71.77% , training accuracy: 0.757\n",
        "\n",
        "## Using dropout layer for first layer(0.25):68.27% , training accuracy: 0.9662\n",
        "\n",
        "## Decreasing batch size(Doesnt seem to do any good)\n",
        "# Batch_size 256 : 15%\n",
        "# Batch_size 750 : 13%  \n",
        "\n",
        "\n",
        "## Early stopping \n",
        "# Patience(5), min_delta(0.001) : 64.46% 56s\n",
        "# Patience(5), min_delta(0.01): 65.6989% 1m30s\n",
        "# Patience(5), min_delta(0.1): 65.86% 57s\n",
        "\n",
        "## L2 regularisation --> Will use this for grid search later\n",
        "# (0.001) 67.58%\n",
        "\n",
        "## L1 regularisation --> Will use this for grid search later\n",
        "# (0.001) 67.15%\n",
        "\n",
        "\n",
        "features = [48,64,128,156]\n",
        "VGG=keras.models.Sequential()\n",
        "\n",
        "VGG.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "#pooling layer\n",
        "VGG.add(layers.MaxPooling2D(2,2))\n",
        "VGG.add(layers.BatchNormalization()) \n",
        "VGG.add(layers.Dropout(0.25))\n",
        "for i in features:\n",
        "\n",
        "#covolution layer\n",
        "  VGG.add(layers.Conv2D(i,(3,3),activation='relu'))\n",
        "#pooling layer\n",
        "  VGG.add(layers.MaxPooling2D(2,2))\n",
        "  VGG.add(layers.BatchNormalization())\n",
        "#  VGG.add(layers.Dropout(0.25))\n",
        "\n",
        "VGG.add(layers.Flatten())\n",
        "#o/p layer\n",
        "VGG.add(layers.Dense(10,activation='softmax',kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.1, # minimium amount of change to count as an improvement\n",
        "    patience=5, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "VGG.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#VGG.summary()\n",
        "VGG.fit(default_gen, validation_data = val_generator, epochs=10,callbacks=[early_stopping])\n",
        "\n",
        "val_loss, val_acc = VGG.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huCvMmF3nqVi"
      },
      "source": [
        "## Tuning parameters ##\n",
        "- The three hyperparameters that will require tuning will be lambda, dropout rate and early stopping.\n",
        "- This stage is about finding the best parameters that returns the best validation accuracy.\n",
        "- Done with the help of the keras tuner package.\n",
        "- Random Search : best validation 0.66\n",
        "- Bayesian Optimisation : best validation 0.61\n",
        "- Final model will use hyper parameters from random search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vAZEIXyosXp"
      },
      "outputs": [],
      "source": [
        "def VGGT(hp):\n",
        "  dpr = hp.Float(\"dpr\", min_value=0.1, max_value=0.9, step=0.05)\n",
        "  #md = hp.Float(\"hp\", min_value=1e-4, max_value=1e-2)\n",
        "  lamb2 = hp.Float(\"lamb2\",min_value=1e-5, max_value=1e-1)\n",
        "  features = [48,64,128,156]  \n",
        "  model=keras.models.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "  #pooling layer\n",
        "  model.add(layers.MaxPooling2D(2,2))\n",
        "  model.add(layers.BatchNormalization()) \n",
        "  model.add(layers.Dropout(dpr))\n",
        "  for i in features:\n",
        "\n",
        "  #covolution layer\n",
        "    model.add(layers.Conv2D(i,(3,3),activation='relu'))\n",
        "  #pooling layer\n",
        "    model.add(layers.MaxPooling2D(2,2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    #model.add(layers.Dropout(0.25))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  #o/p layer\n",
        "  model.add(layers.Dense(10,activation='softmax',kernel_regularizer=regularizers.l2(lamb2)))\n",
        "\n",
        "\n",
        "  initial_learning_rate = 0.001\n",
        "\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "  model.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## RandomSearch\n",
        "VGGT(keras_tuner.HyperParameters())\n",
        "\n",
        "RStuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=VGGT,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=5,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True,\n",
        "    directory=\"assignment_1\",\n",
        "    project_name=\"RandomSearch results\",\n",
        ")\n",
        "RStuner.search(X_train, Y_train, epochs=5,validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEp2vr0Sj0NN",
        "outputId": "6e698efe-1d1b-4c3d-ef81-0e51e1f17ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 01m 28s]\n",
            "val_accuracy: 0.6354838907718658\n",
            "\n",
            "Best val_accuracy So Far: 0.6736558973789215\n",
            "Total elapsed time: 00h 08m 06s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian Optimisation\n",
        "BOtuner = keras_tuner.BayesianOptimization(\n",
        "    hypermodel=VGGT,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=3,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True\n",
        ")\n",
        "BOtuner.search(X_train, Y_train, epochs=3, validation_data=(X_val, Y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbHH26cLhmQZ",
        "outputId": "f48acdb0-6d1d-4c22-8239-3f553008e8f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 01m 15s]\n",
            "val_accuracy: 0.5596774071455002\n",
            "\n",
            "Best val_accuracy So Far: 0.5758064389228821\n",
            "Total elapsed time: 00h 03m 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping, use data augmentation validation set to tune this\n",
        "# Manually tune this one\n",
        "def VGGES():\n",
        "  #dpr = hp.Float(\"dpr\", min_value=0.1, max_value=0.9, step=0.05)\n",
        "  #md = hp.Float(\"hp\", min_value=1e-4, max_value=1e-2)\n",
        "  #lamb2 = hp.Float(\"lamb2\",min_value=1e-5, max_value=1e-1)\n",
        "  features = [48,64,128,156]  \n",
        "  model=keras.models.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\n",
        "  #pooling layer\n",
        "  model.add(layers.MaxPooling2D(2,2))\n",
        "  model.add(layers.BatchNormalization()) \n",
        "  model.add(layers.Dropout(0.2))\n",
        "  for i in features:\n",
        "\n",
        "  #covolution layer\n",
        "    model.add(layers.Conv2D(i,(3,3),activation='relu'))\n",
        "  #pooling layer\n",
        "    model.add(layers.MaxPooling2D(2,2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    #model.add(layers.Dropout(0.25))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  #o/p layer\n",
        "  model.add(layers.Dense(10,activation='softmax',kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "\n",
        "  initial_learning_rate = 0.001\n",
        "\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "  model.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return(model)\n",
        "\n",
        "min_delta_values = [0.1,0.01,0.001,0.0001]\n",
        "for i in min_delta_values:\n",
        "  early_stopping = callbacks.EarlyStopping(\n",
        "      min_delta=i, # minimium amount of change to count as an improvement\n",
        "      patience=5, # how many epochs to wait before stopping\n",
        "      restore_best_weights=True,\n",
        "    )\n",
        "  modelES = VGGES()\n",
        "  modelES.fit(train_datagen.flow(X_train,Y_train,batch_size = 512,subset = \"training\"),\n",
        "           validation_data = train_datagen.flow(X_train,Y_train,batch_size = 512,subset = \"validation\"),callbacks=[early_stopping])\n",
        "  val_loss, val_acc = modelES.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "  print('\\nTest accuracy:', val_acc*100, \"%\")\n"
      ],
      "metadata": {
        "id": "uFw4oZhJ8Ihl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final testing with tuned model ##\n",
        "- 70.9% test accuracy\n"
      ],
      "metadata": {
        "id": "7GKOzhrclzQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting best model\n",
        "best_hps = RStuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "model1 = VGGT(best_hps[0])\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.01, # minimium amount of change to count as an improvement\n",
        "    patience=5, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "model1.fit(x=X_train, y=Y_train, epochs=20,callbacks=[early_stopping])\n",
        "\n",
        "test_loss, test_acc = model1.evaluate(X_test,  Y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjQMHTsilAv8",
        "outputId": "98cab8d4-347a-416f-9c49-cf5ffdb6b287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "233/233 [==============================] - ETA: 0s - loss: 2.4797 - accuracy: 0.4781"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 9s 27ms/step - loss: 2.4797 - accuracy: 0.4781\n",
            "Epoch 2/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 1.3622 - accuracy: 0.6266"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 28ms/step - loss: 1.3613 - accuracy: 0.6271\n",
            "Epoch 3/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 1.1475 - accuracy: 0.6695"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 26ms/step - loss: 1.1464 - accuracy: 0.6700\n",
            "Epoch 4/20\n",
            "232/233 [============================>.] - ETA: 0s - loss: 1.0260 - accuracy: 0.7116"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 27ms/step - loss: 1.0253 - accuracy: 0.7119\n",
            "Epoch 5/20\n",
            "232/233 [============================>.] - ETA: 0s - loss: 0.9453 - accuracy: 0.7457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 27ms/step - loss: 0.9453 - accuracy: 0.7453\n",
            "Epoch 6/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.8586 - accuracy: 0.7739"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 28ms/step - loss: 0.8579 - accuracy: 0.7743\n",
            "Epoch 7/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.7817 - accuracy: 0.8028"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 27ms/step - loss: 0.7812 - accuracy: 0.8030\n",
            "Epoch 8/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.6869 - accuracy: 0.8415"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 28ms/step - loss: 0.6871 - accuracy: 0.8419\n",
            "Epoch 9/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.6069 - accuracy: 0.8696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 28ms/step - loss: 0.6076 - accuracy: 0.8693\n",
            "Epoch 10/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.9065"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 28ms/step - loss: 0.5277 - accuracy: 0.9064\n",
            "Epoch 11/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.9315"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 27ms/step - loss: 0.4451 - accuracy: 0.9314\n",
            "Epoch 12/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.9502"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 7s 28ms/step - loss: 0.3807 - accuracy: 0.9497\n",
            "Epoch 13/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.3305 - accuracy: 0.9647"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 27ms/step - loss: 0.3312 - accuracy: 0.9645\n",
            "Epoch 14/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.9782"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 27ms/step - loss: 0.2817 - accuracy: 0.9782\n",
            "Epoch 15/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9836"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 26ms/step - loss: 0.2428 - accuracy: 0.9837\n",
            "Epoch 16/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 28ms/step - loss: 0.2175 - accuracy: 0.9884\n",
            "Epoch 17/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.2057 - accuracy: 0.9904"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 27ms/step - loss: 0.2059 - accuracy: 0.9903\n",
            "Epoch 18/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9896"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 28ms/step - loss: 0.1946 - accuracy: 0.9896\n",
            "Epoch 19/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9873"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 6s 27ms/step - loss: 0.1967 - accuracy: 0.9872\n",
            "Epoch 20/20\n",
            "231/233 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9900"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r233/233 [==============================] - 7s 28ms/step - loss: 0.1921 - accuracy: 0.9896\n",
            "121/121 - 1s - loss: 1.0995 - accuracy: 0.7090 - 1s/epoch - 10ms/step\n",
            "\n",
            "Test accuracy: 70.90249061584473 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic CNN model from lecture ##"
      ],
      "metadata": {
        "id": "86u7TYbWCPwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw7VXgdzxKso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89381e51-5453-4339-ba55-428c541b8941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "233/233 [==============================] - 9s 32ms/step - loss: 1.8487 - accuracy: 0.3648 - val_loss: 1.4992 - val_accuracy: 0.5102\n",
            "Epoch 2/10\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 1.3054 - accuracy: 0.5737 - val_loss: 1.3270 - val_accuracy: 0.5704\n",
            "Epoch 3/10\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.9265 - accuracy: 0.7010 - val_loss: 1.3116 - val_accuracy: 0.5812\n",
            "Epoch 4/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.5588 - accuracy: 0.8221 - val_loss: 1.5456 - val_accuracy: 0.5667\n",
            "Epoch 5/10\n",
            "233/233 [==============================] - 5s 22ms/step - loss: 0.2473 - accuracy: 0.9252 - val_loss: 2.1420 - val_accuracy: 0.5468\n",
            "Epoch 6/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.1462 - accuracy: 0.9567 - val_loss: 2.3410 - val_accuracy: 0.5586\n",
            "Epoch 7/10\n",
            "233/233 [==============================] - 5s 23ms/step - loss: 0.0824 - accuracy: 0.9769 - val_loss: 2.3663 - val_accuracy: 0.5581\n",
            "Epoch 8/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.0611 - accuracy: 0.9835 - val_loss: 2.9733 - val_accuracy: 0.5403\n",
            "Epoch 9/10\n",
            "233/233 [==============================] - 5s 20ms/step - loss: 0.0381 - accuracy: 0.9888 - val_loss: 3.3420 - val_accuracy: 0.5355\n",
            "Epoch 10/10\n",
            "233/233 [==============================] - 6s 26ms/step - loss: 0.0565 - accuracy: 0.9816 - val_loss: 3.2629 - val_accuracy: 0.5360\n",
            "59/59 - 0s - loss: 3.2629 - accuracy: 0.5360 - 447ms/epoch - 8ms/step\n",
            "\n",
            "Test accuracy: 53.602153062820435 %\n"
          ]
        }
      ],
      "source": [
        "# Basic CNN model\n",
        "BCCN = models.Sequential()\n",
        "BCCN.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.Conv2D(48, (3, 3), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "BCCN.add(layers.Flatten())\n",
        "BCCN.add(layers.Dense(128, activation='relu'))\n",
        "BCCN.add(layers.Dense(10,activation = \"softmax\"))\n",
        "\n",
        "BCCN.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BCCN.fit(default_gen, validation_data = val_generator, epochs=10)\n",
        "\n",
        "test_loss, test_acc = BCCN.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfit ##\n",
        "- Play around with the parameters to maximise training accuracy and at the same time increase validation accuracy. Increase capacity to increase training accuracy.\n",
        "- Overfitted model specifications\n",
        "1. Activation function: Relu\n",
        "2. Kernel size : (4,4)\n",
        "3. Features : [40,80,120,160]\n",
        "4. Optimiser: Adam\n",
        "5. Lr_schedule : Exponential \n",
        "6. Initial LR : 0.0001\n",
        "\n",
        "- Training accuracy by 10th epoch : 0.9984\n",
        "- Validation accuracy : 0.6737\n",
        "- Training time: 51s\n"
      ],
      "metadata": {
        "id": "2t6NBh7IJGFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic CNN model\n",
        "BCCN = models.Sequential()\n",
        "BCCN.add(layers.Conv2D(40, (4, 4), activation='relu', input_shape=(128, 128, 3)))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.BatchNormalization()) \n",
        "BCCN.add(layers.Conv2D(80, (4, 4), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.BatchNormalization()) \n",
        "BCCN.add(layers.Conv2D(120, (4, 4), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.BatchNormalization()) \n",
        "BCCN.add(layers.Conv2D(160, (4, 4), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.BatchNormalization()) \n",
        "BCCN.add(layers.Flatten())\n",
        "BCCN.add(layers.Dense(10,activation = \"softmax\"))\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "BCCN.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BCCN.fit(default_gen, validation_data = val_generator, epochs=20)\n",
        "\n",
        "test_loss, test_acc = BCCN.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNTUeTLBJb8w",
        "outputId": "3fa1034d-0978-4eb5-bae4-874517315c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "233/233 [==============================] - 13s 34ms/step - loss: 1.9654 - accuracy: 0.4198 - val_loss: 4.1100 - val_accuracy: 0.1624\n",
            "Epoch 2/20\n",
            "233/233 [==============================] - 8s 36ms/step - loss: 1.3422 - accuracy: 0.5811 - val_loss: 3.0044 - val_accuracy: 0.2570\n",
            "Epoch 3/20\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 1.0670 - accuracy: 0.6595 - val_loss: 2.4548 - val_accuracy: 0.3925\n",
            "Epoch 4/20\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.8349 - accuracy: 0.7314 - val_loss: 1.4042 - val_accuracy: 0.6032\n",
            "Epoch 5/20\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.6001 - accuracy: 0.7996 - val_loss: 1.7296 - val_accuracy: 0.5532\n",
            "Epoch 6/20\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.4165 - accuracy: 0.8640 - val_loss: 1.4150 - val_accuracy: 0.6097\n",
            "Epoch 7/20\n",
            "233/233 [==============================] - 9s 37ms/step - loss: 0.2561 - accuracy: 0.9196 - val_loss: 1.5226 - val_accuracy: 0.6048\n",
            "Epoch 8/20\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.1562 - accuracy: 0.9562 - val_loss: 1.4429 - val_accuracy: 0.6075\n",
            "Epoch 9/20\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.0916 - accuracy: 0.9754 - val_loss: 1.5533 - val_accuracy: 0.6220\n",
            "Epoch 10/20\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.0736 - accuracy: 0.9817 - val_loss: 1.5842 - val_accuracy: 0.6457\n",
            "Epoch 11/20\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.0591 - accuracy: 0.9857 - val_loss: 1.6354 - val_accuracy: 0.6210\n",
            "Epoch 12/20\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.0361 - accuracy: 0.9921 - val_loss: 1.5733 - val_accuracy: 0.6516\n",
            "Epoch 13/20\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.0263 - accuracy: 0.9941 - val_loss: 1.6040 - val_accuracy: 0.6543\n",
            "Epoch 14/20\n",
            "233/233 [==============================] - 8s 36ms/step - loss: 0.0278 - accuracy: 0.9945 - val_loss: 1.6546 - val_accuracy: 0.6478\n",
            "Epoch 15/20\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.1439 - accuracy: 0.9547 - val_loss: 2.9775 - val_accuracy: 0.5366\n",
            "Epoch 16/20\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.4367 - accuracy: 0.8587 - val_loss: 3.6112 - val_accuracy: 0.5161\n",
            "Epoch 17/20\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.2017 - accuracy: 0.9307 - val_loss: 1.9713 - val_accuracy: 0.6247\n",
            "Epoch 18/20\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.0519 - accuracy: 0.9822 - val_loss: 2.1844 - val_accuracy: 0.6065\n",
            "Epoch 19/20\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.0188 - accuracy: 0.9960 - val_loss: 1.7839 - val_accuracy: 0.6651\n",
            "Epoch 20/20\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 1.8160 - val_accuracy: 0.6505\n",
            "59/59 - 1s - loss: 1.8160 - accuracy: 0.6505 - 625ms/epoch - 11ms/step\n",
            "\n",
            "Test accuracy: 65.05376100540161 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization ##\n",
        "- Implementing restrictions and reducing capacity to increase validation accuracy at the expense of training accuracy\n",
        "1. Add dropout layer to each iteration\n",
        "- 0.1: 61.88%\n",
        "- 0.2: 59.7%\n",
        "- 0.4: 66%\n",
        "- 0.6: 63%\n",
        "2. Early stopping\n",
        "- Generally lower validation accuracy than model but not by much\n",
        "3. L2 and L1 regularisation\n",
        "- l1_l2: 65.91%, however it is worth to note as there are epochs with high VA\n",
        "- l1: 65.698%, high VAs in validation\n",
        "- l2: 71.29%, and high VAs\n",
        "4. Kernel size\n",
        "- (4,4) : 67.36%\n",
        "- (3,3) : 63.7%\n",
        "- (2,2) :  61%\n",
        "\n",
        "Regularizations that will be used:\n",
        "1. L1 regularisation\n",
        "2. Early stopping\n",
        "3. Dropout\n",
        "\n",
        "Regularised model VA : 68.064%"
      ],
      "metadata": {
        "id": "ZKHDYPeFMeSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic CNN model\n",
        "BCCN = models.Sequential()\n",
        "BCCN.add(layers.Conv2D(40, (4, 4), activation='relu', input_shape=(128, 128, 3)))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.BatchNormalization()) \n",
        "BCCN.add(layers.Dropout(0.25))\n",
        "#----------------------------------------------------------\n",
        "BCCN.add(layers.Conv2D(80, (4, 4), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.BatchNormalization()) \n",
        "BCCN.add(layers.Dropout(0.25))\n",
        "#----------------------------------------------------------\n",
        "BCCN.add(layers.Conv2D(120, (4, 4), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.BatchNormalization())\n",
        "BCCN.add(layers.Dropout(0.25))\n",
        "#----------------------------------------------------------\n",
        "BCCN.add(layers.Conv2D(160, (4, 4), activation='relu'))\n",
        "BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "BCCN.add(layers.BatchNormalization())\n",
        "BCCN.add(layers.Dropout(0.25))\n",
        "#----------------------------------------------------------\n",
        "BCCN.add(layers.Flatten())\n",
        "BCCN.add(layers.Dense(10,activation = \"softmax\",kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
        "    patience=5, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "BCCN.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BCCN.fit(default_gen, validation_data = val_generator, epochs=20, callbacks=[early_stopping])\n",
        "\n",
        "val_loss, val_acc = BCCN.evaluate(X_val,  Y_val, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', val_acc*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT_V5Rf-Mj8g",
        "outputId": "009e8da4-3d22-4e46-fdb7-79624159caf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "233/233 [==============================] - 15s 49ms/step - loss: 2.3748 - accuracy: 0.3735 - val_loss: 3.8874 - val_accuracy: 0.1608\n",
            "Epoch 2/20\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 1.7574 - accuracy: 0.5227 - val_loss: 2.4801 - val_accuracy: 0.3742\n",
            "Epoch 3/20\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 1.4673 - accuracy: 0.5904 - val_loss: 2.0054 - val_accuracy: 0.4828\n",
            "Epoch 4/20\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 1.2634 - accuracy: 0.6404 - val_loss: 1.5097 - val_accuracy: 0.5919\n",
            "Epoch 5/20\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 1.1561 - accuracy: 0.6795 - val_loss: 1.6974 - val_accuracy: 0.5785\n",
            "Epoch 6/20\n",
            "233/233 [==============================] - 11s 48ms/step - loss: 1.0547 - accuracy: 0.7039 - val_loss: 1.9060 - val_accuracy: 0.4473\n",
            "Epoch 7/20\n",
            "233/233 [==============================] - 11s 46ms/step - loss: 0.9683 - accuracy: 0.7335 - val_loss: 2.7192 - val_accuracy: 0.3817\n",
            "Epoch 8/20\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 0.9057 - accuracy: 0.7433 - val_loss: 1.8880 - val_accuracy: 0.5355\n",
            "Epoch 9/20\n",
            "233/233 [==============================] - 11s 45ms/step - loss: 0.7951 - accuracy: 0.7862 - val_loss: 1.2944 - val_accuracy: 0.6699\n",
            "Epoch 10/20\n",
            "233/233 [==============================] - 11s 45ms/step - loss: 0.7124 - accuracy: 0.8158 - val_loss: 1.2709 - val_accuracy: 0.6651\n",
            "Epoch 11/20\n",
            "233/233 [==============================] - 11s 49ms/step - loss: 0.6477 - accuracy: 0.8431 - val_loss: 1.3788 - val_accuracy: 0.6527\n",
            "Epoch 12/20\n",
            "233/233 [==============================] - 11s 45ms/step - loss: 0.6011 - accuracy: 0.8609 - val_loss: 1.4147 - val_accuracy: 0.6371\n",
            "Epoch 13/20\n",
            "233/233 [==============================] - 11s 48ms/step - loss: 0.5857 - accuracy: 0.8670 - val_loss: 1.3071 - val_accuracy: 0.6634\n",
            "Epoch 14/20\n",
            "233/233 [==============================] - 11s 45ms/step - loss: 0.5279 - accuracy: 0.8925 - val_loss: 1.6006 - val_accuracy: 0.5892\n",
            "Epoch 15/20\n",
            "233/233 [==============================] - 11s 47ms/step - loss: 0.4916 - accuracy: 0.9008 - val_loss: 1.4302 - val_accuracy: 0.6629\n",
            "59/59 - 1s - loss: 1.2709 - accuracy: 0.6651 - 604ms/epoch - 10ms/step\n",
            "\n",
            "Test accuracy: 66.50537848472595 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning ##\n",
        "- Manually tune the hyperparameters"
      ],
      "metadata": {
        "id": "CSZ_h-mrOD5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BCCNT(hp): \n",
        "  dpr = hp.Float(\"dpr\", min_value=0.1, max_value=0.9, step=0.05)\n",
        "  lamb2 = hp.Float(\"lamb2\",min_value=1e-5, max_value=1e-1)\n",
        "  initial_learning_rate = 0.001\n",
        "  BCCN = models.Sequential()\n",
        "  BCCN.add(layers.Conv2D(40, (4, 4), activation='relu', input_shape=(128, 128, 3)))\n",
        "  BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "  BCCN.add(layers.BatchNormalization()) \n",
        "  BCCN.add(layers.Dropout(dpr))\n",
        "  #----------------------------------------------------------\n",
        "  BCCN.add(layers.Conv2D(80, (4, 4), activation='relu'))\n",
        "  BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "  BCCN.add(layers.BatchNormalization()) \n",
        "  BCCN.add(layers.Dropout(dpr))\n",
        "  #----------------------------------------------------------\n",
        "  BCCN.add(layers.Conv2D(120, (4, 4), activation='relu'))\n",
        "  BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "  BCCN.add(layers.BatchNormalization())\n",
        "  BCCN.add(layers.Dropout(dpr))\n",
        "  #----------------------------------------------------------\n",
        "  BCCN.add(layers.Conv2D(160, (4, 4), activation='relu'))\n",
        "  BCCN.add(layers.MaxPooling2D((2, 2)))\n",
        "  BCCN.add(layers.BatchNormalization())\n",
        "  BCCN.add(layers.Dropout(dpr))\n",
        "  #----------------------------------------------------------\n",
        "  BCCN.add(layers.Flatten())\n",
        "  BCCN.add(layers.Dense(10,activation = \"softmax\",kernel_regularizer=regularizers.l2(lamb2)))\n",
        "\n",
        "  #early_stopping = callbacks.EarlyStopping(\n",
        "  #   min_delta=md, # minimium amount of change to count as an improvement\n",
        "  #    patience=5, # how many epochs to wait before stopping\n",
        "  #    restore_best_weights=True,\n",
        "  #)\n",
        "\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "      initial_learning_rate,\n",
        "      decay_steps=100000,\n",
        "      decay_rate=0.96,\n",
        "      staircase=True)\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "  BCCN.compile(optimizer=opt,\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "  return(BCCN)\n",
        "\n"
      ],
      "metadata": {
        "id": "fsuJq81UOHmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomSearch\n",
        "BCCNT(keras_tuner.HyperParameters())\n",
        "\n",
        "RStuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=BCCNT,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=3,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True,\n",
        "    directory=\"assignment_1\",\n",
        "    project_name=\"RandomSearch results\",\n",
        ")\n",
        "RStuner.search(X_train, Y_train, epochs=3, validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZnaeC-1JNUc",
        "outputId": "1bcd657a-797c-4535-8d72-df24e55e4399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 02m 24s]\n",
            "val_accuracy: 0.1620967760682106\n",
            "\n",
            "Best val_accuracy So Far: 0.5830645263195038\n",
            "Total elapsed time: 00h 13m 01s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian Optimisation\n",
        "BOtuner = keras_tuner.BayesianOptimization(\n",
        "    hypermodel=BCCNT,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=3,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True\n",
        ")\n",
        "BOtuner.search(X_train, Y_train, epochs=3, validation_data=(X_val, Y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm63Tqf0JSRt",
        "outputId": "dae16d20-9d2a-4bbe-f70a-c0a1aec9f66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 02m 53s]\n",
            "val_accuracy: 0.4857526868581772\n",
            "\n",
            "Best val_accuracy So Far: 0.5975806415081024\n",
            "Total elapsed time: 00h 13m 02s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final testing ##"
      ],
      "metadata": {
        "id": "exzH19l0OIaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting best model\n",
        "best_hps = RStuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "model1 = BCCNT(best_hps[0])\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.1, # minimium amount of change to count as an improvement\n",
        "    patience=5, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "model1.fit(x=default_gen, validation_data=val_generator, epochs=13,callbacks=[early_stopping])\n",
        "\n",
        "test_loss, test_acc = model1.evaluate(X_test,  Y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZitDUs4OJ9j",
        "outputId": "155a8d4d-c5ce-47c0-b5a0-df55c0367013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "233/233 [==============================] - 14s 46ms/step - loss: 3.0419 - accuracy: 0.3916 - val_loss: 3.9516 - val_accuracy: 0.1258\n",
            "Epoch 2/13\n",
            "233/233 [==============================] - 11s 45ms/step - loss: 1.8160 - accuracy: 0.5457 - val_loss: 2.1883 - val_accuracy: 0.4215\n",
            "Epoch 3/13\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 1.4859 - accuracy: 0.6005 - val_loss: 1.7972 - val_accuracy: 0.5296\n",
            "Epoch 4/13\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 1.3520 - accuracy: 0.6397 - val_loss: 2.2526 - val_accuracy: 0.4898\n",
            "Epoch 5/13\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 1.2819 - accuracy: 0.6614 - val_loss: 2.1426 - val_accuracy: 0.4382\n",
            "Epoch 6/13\n",
            "233/233 [==============================] - 11s 47ms/step - loss: 1.2194 - accuracy: 0.6826 - val_loss: 1.4930 - val_accuracy: 0.5973\n",
            "Epoch 7/13\n",
            "233/233 [==============================] - 11s 47ms/step - loss: 1.1384 - accuracy: 0.7004 - val_loss: 2.2819 - val_accuracy: 0.4597\n",
            "Epoch 8/13\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 1.0784 - accuracy: 0.7332 - val_loss: 1.4825 - val_accuracy: 0.6091\n",
            "Epoch 9/13\n",
            "233/233 [==============================] - 11s 45ms/step - loss: 1.0076 - accuracy: 0.7620 - val_loss: 1.6938 - val_accuracy: 0.5667\n",
            "Epoch 10/13\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.9943 - accuracy: 0.7628 - val_loss: 1.3389 - val_accuracy: 0.6672\n",
            "Epoch 11/13\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 0.9450 - accuracy: 0.7906 - val_loss: 1.3240 - val_accuracy: 0.6694\n",
            "Epoch 12/13\n",
            "233/233 [==============================] - 10s 45ms/step - loss: 0.9218 - accuracy: 0.8012 - val_loss: 1.3963 - val_accuracy: 0.6489\n",
            "Epoch 13/13\n",
            "233/233 [==============================] - 11s 47ms/step - loss: 0.8823 - accuracy: 0.8112 - val_loss: 1.4668 - val_accuracy: 0.6403\n",
            "121/121 - 2s - loss: 1.4777 - accuracy: 0.6354 - 2s/epoch - 12ms/step\n",
            "\n",
            "Test accuracy: 63.53734731674194 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S5d1aBPIS0Ft"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}