{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f0c548f8",
      "metadata": {
        "id": "f0c548f8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import csc_matrix\n",
        "import tqdm\n",
        "import jax \n",
        "from jax.config import config\n",
        "config.update('jax_enable_x64', True)  # often needed for LBFGS that requires high-precision\n",
        "\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd /content/drive/MyDrive/DSA4212/assignment_2\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SSypFmUm_Vi",
        "outputId": "d4df916f-26f2-4b01-f09c-a61b10ff2336"
      },
      "id": "4SSypFmUm_Vi",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/DSA4212/assignment_2\n",
            " \u001b[0m\u001b[01;34massignment_2_data\u001b[0m/\n",
            " dsa4212_2022_assignment_2-2.pdf\n",
            "'Extension using collaborative filtering'\n",
            "'Factor model from scratch.ipynb'\n",
            "'Factor model using lecture and extensions'\n",
            "'Normal baseline model'\n",
            " train_data.csv\n",
            " tutorial_matrix_factorization_CLASS.ipynb\n",
            " tutorial_matrix_factorization.ipynb\n",
            " tutorial_newton.ipynb\n",
            " tutorial_reconstruction.ipynb\n",
            " valid_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1c14b80a",
      "metadata": {
        "id": "1c14b80a"
      },
      "outputs": [],
      "source": [
        "anime_data = pd.read_csv('assignment_2_data/assignment_2_anime.csv')\n",
        "train_data = pd.read_csv('assignment_2_data/assignment_2_ratings_train.csv')\n",
        "test_data = pd.read_csv('assignment_2_data/assignment_2_ratings_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41702280",
      "metadata": {
        "id": "41702280"
      },
      "source": [
        "## Splitting training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "946470ac",
      "metadata": {
        "id": "946470ac"
      },
      "outputs": [],
      "source": [
        "train, valid = train_test_split(train_data, test_size = 0.2)\n",
        "\n",
        "# Reset index for train and valid\n",
        "train = train.reset_index()[['user_id', 'anime_id', 'rating']]\n",
        "valid = valid.reset_index()[['user_id', 'anime_id', 'rating']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e35d5077",
      "metadata": {
        "id": "e35d5077"
      },
      "source": [
        "## Encoding columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "27ae0f8f",
      "metadata": {
        "id": "27ae0f8f"
      },
      "outputs": [],
      "source": [
        "def encode_column(column):\n",
        "    keys = column.unique()\n",
        "    key_to_id = {key:idx for idx,key in enumerate(keys)}\n",
        "    return key_to_id, np.array([key_to_id[x] for x in column]), len(keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9a33bd70",
      "metadata": {
        "id": "9a33bd70"
      },
      "outputs": [],
      "source": [
        "def encode_df(data):\n",
        "    anime_ids, data['anime_id'], num_anime = encode_column(data['anime_id'])\n",
        "    user_ids, data['user_id'], num_users = encode_column(data['user_id'])\n",
        "    return data, num_users, num_anime, user_ids, anime_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "0ec92a58",
      "metadata": {
        "id": "0ec92a58"
      },
      "outputs": [],
      "source": [
        "train_data, num_users, num_anime, user_ids, anime_ids = encode_df(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d12e241f",
      "metadata": {
        "id": "d12e241f"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(n, K):\n",
        "    \"\"\"\n",
        "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
        "    n: number of items/users\n",
        "    K: number of factors in the embedding \n",
        "    \"\"\"\n",
        "    return 11*np.random.random((n, K)) / K"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d241333",
      "metadata": {
        "id": "9d241333"
      },
      "source": [
        "## Create sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "69562d99",
      "metadata": {
        "id": "69562d99"
      },
      "outputs": [],
      "source": [
        "def sparse_matrix_init(arraydata, rows, cols, colname): \n",
        "    return csc_matrix((arraydata[colname].values, (arraydata['user_id'].values, arraydata['anime_id'].values)), shape=(rows, cols))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331f7288",
      "metadata": {
        "id": "331f7288"
      },
      "source": [
        "## Prediction without doing U x V transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0b7a4dc7",
      "metadata": {
        "id": "0b7a4dc7"
      },
      "outputs": [],
      "source": [
        "def predict(data, encoded_user, encoded_anime):\n",
        "    data['prediction'] = np.sum(np.multiply(encoded_anime[data['anime_id']], encoded_user[data['user_id']]), axis = 1)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b4164921",
      "metadata": {
        "id": "b4164921"
      },
      "outputs": [],
      "source": [
        "def mse(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    MSE = np.sum((A - A_approx).power(2))/data.shape[0]\n",
        "    \n",
        "    return MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "bc51da7a",
      "metadata": {
        "id": "bc51da7a"
      },
      "outputs": [],
      "source": [
        "def gradient(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    \n",
        "    grad_user = (-2/data.shape[0])*((A - A_approx)*encoded_anime)\n",
        "    grad_anime = (-2/data.shape[0])*((A - A_approx).T*encoded_user) \n",
        "    \n",
        "    return grad_user, grad_anime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e0024847",
      "metadata": {
        "id": "e0024847"
      },
      "outputs": [],
      "source": [
        "def model(data, encoded_user, encoded_anime, iter, lr):\n",
        "    \n",
        "    for i in tqdm.tqdm(range(iter)):\n",
        "        grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "        \n",
        "        encoded_user = encoded_user - lr*grad_user\n",
        "        encoded_anime = encoded_anime - lr*grad_anime\n",
        "\n",
        "    return encoded_user, encoded_anime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "755614b6",
      "metadata": {
        "id": "755614b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbdfbdf3-4e1e-451a-e424-06a3da59e07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [02:45<00:00,  1.65s/it]\n"
          ]
        }
      ],
      "source": [
        "encoded_user = create_embeddings(num_users, 3)\n",
        "encoded_anime = create_embeddings(num_anime, 3)\n",
        "\n",
        "encoded_user, encoded_anime = model(train_data, encoded_user, encoded_anime, 100, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "72dfa774",
      "metadata": {
        "id": "72dfa774"
      },
      "outputs": [],
      "source": [
        "def encode_new_data(valid, user_ids, anime_ids):\n",
        "    \"\"\" Encodes valid_df with the same encoding as train_df.\n",
        "    \"\"\"\n",
        "    df_val_chosen = valid['anime_id'].isin(anime_ids.keys()) & valid['user_id'].isin(user_ids.keys())\n",
        "    valid_data = valid[df_val_chosen]\n",
        "    valid_data['anime_id'] =  np.array([anime_ids[x] for x in valid_data['anime_id']])\n",
        "    valid_data['user_id'] = np.array([user_ids[x] for x in valid_data['user_id']])\n",
        "    return valid_data\n",
        "\n",
        "valid_data = encode_new_data(valid, user_ids, anime_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "e3382358",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3382358",
        "outputId": "ee18c7c6-cc99-44a5-fa04-39049c9a11b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.314559860986886 14.297594557583956\n"
          ]
        }
      ],
      "source": [
        "train_mse = mse(train_data, encoded_user, encoded_anime)\n",
        "val_mse = mse(valid_data, encoded_user, encoded_anime)\n",
        "print(train_mse, val_mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different experiments with the base model ## \n",
        "0. Base model  \n",
        "train_MSE: 14.31  \n",
        "valid_MSE: 14.30\n",
        "\n",
        "1. Changing parameters  \n",
        "- Changing number of latent factors  \n",
        "10:  \n",
        "train_MSE, 14.13  \n",
        "valid_MSE, 14.16  \n",
        "20:  \n",
        "train_MSE, 27.42  \n",
        "valid_MSE, 27.44\n",
        "\n",
        "- Changing learning rate  \n",
        "This indicates that base model have not converged yet    \n",
        "10:    \n",
        "train_MSE: 5.82   \n",
        "valid_MSE: 5.86  \n",
        "20:  \n",
        "train_MSE: 6.28  \n",
        "valid_MSE: 6.27  \n",
        "Decaying LR:  \n",
        "train_MSE: 5.83   \n",
        "valid_MSE: 5.84\n",
        "\n",
        "- Different distribution for initialisation for embeddings  \n",
        "N(0,1):  \n",
        "train_MSE: 142.78  \n",
        "valid_MSE: 143.00  \n",
        "Initialisation values might be too small  \n",
        "\n",
        "2. Changing gradient descent  \n",
        "- Alternative minimisation  \n",
        "Anime first then user  \n",
        "train_MSE: 10.87  \n",
        "valid_MSE: 10.88  \n",
        "User first then anime  \n",
        "train_MSE: 5.53  \n",
        "valid_MSE: 5.53\n",
        "\n",
        "- Gradient descent with momentum  \n",
        "B = 0.9  \n",
        "train_MSE: 5.98  \n",
        "valid_MSE: 5.98\n",
        "\n",
        "\n",
        "3. Changing loss functions  \n",
        "- Ridge regularisation  \n",
        "B = 0.1  \n",
        "train_MSE: 34.11  \n",
        "valid_MSE: 34.08\n",
        "\n",
        "4. Changing prediction method  \n",
        "- Lower and upper bound predictions, basically if scores below one we make them one and if scores above 10 we make them 10.  \n",
        "  \n"
      ],
      "metadata": {
        "id": "fDMuqg9Za1E8"
      },
      "id": "fDMuqg9Za1E8"
    },
    {
      "cell_type": "code",
      "source": [
        "def ridge_mse(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    MSE = np.sum((A - A_approx).power(2))/data.shape[0] + 0.1*np.sum(encoded_anime^2) + 0.1*np.sum(encoded_user^2)\n",
        "    \n",
        "    return MSE\n",
        "\n",
        "def ridge_gradient(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    \n",
        "    lamb = 0.001\n",
        "    grad_user = (-2/data.shape[0])*((A - A_approx)*encoded_anime) + 2*lamb*encoded_user\n",
        "    grad_anime = (-2/data.shape[0])*((A - A_approx).T*encoded_user) + 2*lamb*encoded_anime\n",
        "    \n",
        "    return grad_user, grad_anime\n",
        "\n",
        "def create_embeddings(n, K):\n",
        "    \"\"\"\n",
        "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
        "    n: number of items/users\n",
        "    K: number of factors in the embedding \n",
        "    \"\"\"\n",
        "    return 11*np.random.random((n, K)) / K\n",
        "\n",
        "def model(data, encoded_user, encoded_anime, iter, lr):\n",
        "   # B = 0.9\n",
        "    for i in tqdm.tqdm(range(iter)):\n",
        "      #if (i == 0):\n",
        "     # encoded_user_lag = encoded_user\n",
        "     # encoded_anime_lag = encoded_anime\n",
        "      grad_user, grad_anime = ridge_gradient(data, encoded_user, encoded_anime)\n",
        "      encoded_user = encoded_user - lr*grad_user\n",
        "      encoded_anime = encoded_anime - lr*grad_anime\n",
        "      #user_change = encoded_user - encoded_user_lag\n",
        "      #anime_change = encoded_anime - encoded_anime_lag\n",
        "      #else:\n",
        "      #  encoded_user_lag = encoded_user\n",
        "      #  encoded_anime_lag = encoded_anime\n",
        "      #  grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "      #  encoded_user = encoded_user - lr*grad_user + B*(user_change)\n",
        "      #  encoded_anime = encoded_anime - lr*grad_anime + B*(anime_change)\n",
        "      #  user_change = encoded_user - encoded_user_lag\n",
        "      #  anime_change = encoded_anime - encoded_anime_lag\n",
        "    #for i in tqdm.tqdm(range(iter)):\n",
        "     #   grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "     #   #encoded_user = encoded_user - lr*grad_user\n",
        "     #   encoded_anime = encoded_anime - lr*grad_anime\n",
        "\n",
        "    return encoded_user, encoded_anime\n",
        "\n",
        "encoded_user = create_embeddings(num_users, 3)\n",
        "encoded_anime = create_embeddings(num_anime, 3)\n",
        "\n",
        "encoded_user, encoded_anime = model(train_data, encoded_user, encoded_anime, 100, 10)\n",
        "\n",
        "train_mse = mse(train_data, encoded_user, encoded_anime)\n",
        "val_mse = mse(valid_data, encoded_user, encoded_anime)\n",
        "print(train_mse, val_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zUdOhzqb6IU",
        "outputId": "c83345c3-dd23-4131-9e50-728f44334417"
      },
      "id": "9zUdOhzqb6IU",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [02:44<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.11222227641071 34.08283701338232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rate_getter = lambda x: 1 if x<1 else (10 if x>10 else x) \n",
        "vfunc = onp.vectorize(rate_getter)\n",
        "#a = U_init[u_list.astype(int)] * V_init[v_list.astype(int)]\n",
        "#b = a.sum(axis = 1)\n",
        "#int_mat = U_init[u_list.astype(int)] * V_init[v_list.astype(int)]\n",
        "#predictions = vfunc(int_mat.sum(axis = 1))\n",
        "#MSE = onp.mean( (predictions - ratings_list)**2 )\n",
        "#predictions = int_mat.sum(axis = 1)\n",
        "#predictions.shape"
      ],
      "metadata": {
        "id": "VQCev5J5_4O1"
      },
      "id": "VQCev5J5_4O1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}