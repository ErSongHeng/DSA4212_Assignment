{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c548f8",
      "metadata": {
        "id": "f0c548f8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import csc_matrix\n",
        "import tqdm\n",
        "import jax \n",
        "from jax.config import config\n",
        "config.update('jax_enable_x64', True)  # often needed for LBFGS that requires high-precision\n",
        "\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd /content/drive/MyDrive/DSA4212/assignment_2\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SSypFmUm_Vi",
        "outputId": "96ed88f5-28d9-4571-c71a-34f967281da6"
      },
      "id": "4SSypFmUm_Vi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/DSA4212/assignment_2\n",
            " \u001b[0m\u001b[01;34massignment_2_data\u001b[0m/\n",
            " dsa4212_2022_assignment_2-2.pdf\n",
            "'Extension using collaborative filtering'\n",
            "'Factor model from scratch.ipynb'\n",
            "'Factor model using lecture and extensions'\n",
            "'Neural network based collaborative filtering.ipynb'\n",
            "'Normal baseline model'\n",
            " train_data.csv\n",
            " tutorial_matrix_factorization_CLASS.ipynb\n",
            " tutorial_matrix_factorization.ipynb\n",
            " tutorial_newton.ipynb\n",
            " tutorial_reconstruction.ipynb\n",
            " valid_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c14b80a",
      "metadata": {
        "id": "1c14b80a"
      },
      "outputs": [],
      "source": [
        "anime_data = pd.read_csv('assignment_2_data/assignment_2_anime.csv')\n",
        "train_data = pd.read_csv('assignment_2_data/assignment_2_ratings_train.csv')\n",
        "test_data = pd.read_csv('assignment_2_data/assignment_2_ratings_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41702280",
      "metadata": {
        "id": "41702280"
      },
      "source": [
        "## Splitting training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946470ac",
      "metadata": {
        "id": "946470ac"
      },
      "outputs": [],
      "source": [
        "train, valid = train_test_split(train_data, test_size = 0.2)\n",
        "\n",
        "# Reset index for train and valid\n",
        "train = train.reset_index()[['user_id', 'anime_id', 'rating']]\n",
        "valid = valid.reset_index()[['user_id', 'anime_id', 'rating']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e35d5077",
      "metadata": {
        "id": "e35d5077"
      },
      "source": [
        "## Encoding columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ae0f8f",
      "metadata": {
        "id": "27ae0f8f"
      },
      "outputs": [],
      "source": [
        "def encode_column(column):\n",
        "    keys = column.unique()\n",
        "    key_to_id = {key:idx for idx,key in enumerate(keys)}\n",
        "    return key_to_id, np.array([key_to_id[x] for x in column]), len(keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a33bd70",
      "metadata": {
        "id": "9a33bd70"
      },
      "outputs": [],
      "source": [
        "def encode_df(data):\n",
        "    anime_ids, data['anime_id'], num_anime = encode_column(data['anime_id'])\n",
        "    user_ids, data['user_id'], num_users = encode_column(data['user_id'])\n",
        "    return data, num_users, num_anime, user_ids, anime_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ec92a58",
      "metadata": {
        "id": "0ec92a58"
      },
      "outputs": [],
      "source": [
        "train_data, num_users, num_anime, user_ids, anime_ids = encode_df(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d12e241f",
      "metadata": {
        "id": "d12e241f"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(n, K):\n",
        "    \"\"\"\n",
        "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
        "    n: number of items/users\n",
        "    K: number of factors in the embedding \n",
        "    \"\"\"\n",
        "    return 11*np.random.random((n, K)) / K"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d241333",
      "metadata": {
        "id": "9d241333"
      },
      "source": [
        "## Create sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69562d99",
      "metadata": {
        "id": "69562d99"
      },
      "outputs": [],
      "source": [
        "def sparse_matrix_init(arraydata, rows, cols, colname): \n",
        "    return csc_matrix((arraydata[colname].values, (arraydata['user_id'].values, arraydata['anime_id'].values)), shape=(rows, cols))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331f7288",
      "metadata": {
        "id": "331f7288"
      },
      "source": [
        "## Prediction without doing U x V transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7a4dc7",
      "metadata": {
        "id": "0b7a4dc7"
      },
      "outputs": [],
      "source": [
        "def predict(data, encoded_user, encoded_anime):\n",
        "    data['prediction'] = np.sum(np.multiply(encoded_anime[data['anime_id']], encoded_user[data['user_id']]), axis = 1)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4164921",
      "metadata": {
        "id": "b4164921"
      },
      "outputs": [],
      "source": [
        "def mse(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    MSE = np.sum((A - A_approx).power(2))/data.shape[0]\n",
        "    \n",
        "    return MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc51da7a",
      "metadata": {
        "id": "bc51da7a"
      },
      "outputs": [],
      "source": [
        "def gradient(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    \n",
        "    grad_user = (-2/data.shape[0])*((A - A_approx)*encoded_anime)\n",
        "    grad_anime = (-2/data.shape[0])*((A - A_approx).T*encoded_user) \n",
        "    \n",
        "    return grad_user, grad_anime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0024847",
      "metadata": {
        "id": "e0024847"
      },
      "outputs": [],
      "source": [
        "def model(data, encoded_user, encoded_anime, iter, lr):\n",
        "    \n",
        "    for i in tqdm.tqdm(range(iter)):\n",
        "        grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "        \n",
        "        encoded_user = encoded_user - lr*grad_user\n",
        "        encoded_anime = encoded_anime - lr*grad_anime\n",
        "\n",
        "    return encoded_user, encoded_anime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "755614b6",
      "metadata": {
        "id": "755614b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e7a161-16fd-4954-f618-ee170f77d9e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [02:13<00:00,  1.34s/it]\n"
          ]
        }
      ],
      "source": [
        "encoded_user = create_embeddings(num_users, 3)\n",
        "encoded_anime = create_embeddings(num_anime, 3)\n",
        "\n",
        "encoded_user, encoded_anime = model(train_data, encoded_user, encoded_anime, 100, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72dfa774",
      "metadata": {
        "id": "72dfa774"
      },
      "outputs": [],
      "source": [
        "def encode_new_data(valid, user_ids, anime_ids):\n",
        "    \"\"\" Encodes valid_df with the same encoding as train_df.\n",
        "    \"\"\"\n",
        "    df_val_chosen = valid['anime_id'].isin(anime_ids.keys()) & valid['user_id'].isin(user_ids.keys())\n",
        "    valid_data = valid[df_val_chosen]\n",
        "    valid_data['anime_id'] =  np.array([anime_ids[x] for x in valid_data['anime_id']])\n",
        "    valid_data['user_id'] = np.array([user_ids[x] for x in valid_data['user_id']])\n",
        "    return valid_data\n",
        "\n",
        "valid_data = encode_new_data(valid, user_ids, anime_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3382358",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3382358",
        "outputId": "c1c5847b-744c-410c-9d48-775c7dcbcb5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.158489381342063 14.136188332086512\n"
          ]
        }
      ],
      "source": [
        "train_mse = mse(train_data, encoded_user, encoded_anime)\n",
        "val_mse = mse(valid_data, encoded_user, encoded_anime)\n",
        "print(train_mse, val_mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different experiments with the base model ## \n",
        "0. Base model  \n",
        "train_MSE: 14.31  \n",
        "valid_MSE: 14.30\n",
        "\n",
        "1. Changing parameters  \n",
        "- Changing number of latent factors  \n",
        "10:  \n",
        "train_MSE, 14.13  \n",
        "valid_MSE, 14.16  \n",
        "20:  \n",
        "train_MSE, 27.42  \n",
        "valid_MSE, 27.44\n",
        "\n",
        "- Changing learning rate  \n",
        "This indicates that base model have not converged yet    \n",
        "10:    \n",
        "train_MSE: 5.82   \n",
        "valid_MSE: 5.86  \n",
        "20:  \n",
        "train_MSE: 6.28  \n",
        "valid_MSE: 6.27  \n",
        "Decaying LR:  \n",
        "train_MSE: 5.83   \n",
        "valid_MSE: 5.84\n",
        "\n",
        "- Different distribution for initialisation for embeddings  \n",
        "N(0,1):  \n",
        "train_MSE: 142.78  \n",
        "valid_MSE: 143.00  \n",
        "Initialisation values might be too small  \n",
        "\n",
        "2. Changing gradient descent  \n",
        "- Alternative minimisation  \n",
        "Anime first then user  \n",
        "train_MSE: 10.87  \n",
        "valid_MSE: 10.88  \n",
        "User first then anime  \n",
        "train_MSE: 5.53  \n",
        "valid_MSE: 5.53\n",
        "\n",
        "- Gradient descent with momentum  \n",
        "B = 0.9  \n",
        "train_MSE: 5.98  \n",
        "test_MSE: 1.94 \n",
        "\n",
        "\n",
        "3. Changing loss functions  \n",
        "- Ridge regularisation  \n",
        "B = 0.1  \n",
        "train_MSE: 34.11  \n",
        "valid_MSE: 34.08\n",
        "\n",
        "4. Changing prediction method  \n",
        "- Lower and upper bound predictions, basically if scores below one we make them one and if scores above 10 we make them 10.  \n",
        "train_MSE: 33.174  \n",
        "valid_MSE: 33.14\n"
      ],
      "metadata": {
        "id": "fDMuqg9Za1E8"
      },
      "id": "fDMuqg9Za1E8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code below is for experimentation that only require small tweaks ##"
      ],
      "metadata": {
        "id": "QZuSmmMf0tPt"
      },
      "id": "QZuSmmMf0tPt"
    },
    {
      "cell_type": "code",
      "source": [
        "rate_getter = lambda x: 1 if x<1 else (10 if x>10 else x) \n",
        "vfunc = np.vectorize(rate_getter)\n",
        "\n",
        "def alt_predict(data, encoded_user, encoded_anime):\n",
        "    data['prediction'] = vfunc(np.sum(np.multiply(encoded_anime[data['anime_id']], encoded_user[data['user_id']]), axis = 1))\n",
        "    return data\n",
        "\n",
        "def mse(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(alt_predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    MSE = np.sum((A - A_approx).power(2))/data.shape[0] \n",
        "    \n",
        "    return MSE\n",
        "\n",
        "def gradient(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(alt_predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    \n",
        "    lamb = 0.001\n",
        "    grad_user = (-2/data.shape[0])*((A - A_approx)*encoded_anime) + 2*lamb*encoded_user\n",
        "    grad_anime = (-2/data.shape[0])*((A - A_approx).T*encoded_user) + 2*lamb*encoded_anime\n",
        "    \n",
        "    return grad_user, grad_anime\n",
        "\n",
        "def create_embeddings(n, K):\n",
        "    \"\"\"\n",
        "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
        "    n: number of items/users\n",
        "    K: number of factors in the embedding \n",
        "    \"\"\"\n",
        "    return 11*np.random.random((n, K)) / K\n",
        "\n",
        "def model(data, encoded_user, encoded_anime, iter, lr):\n",
        "   # B = 0.9\n",
        "    for i in tqdm.tqdm(range(iter)):\n",
        "      #if (i == 0):\n",
        "     # encoded_user_lag = encoded_user\n",
        "     # encoded_anime_lag = encoded_anime\n",
        "      grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "      encoded_user = encoded_user - lr*grad_user\n",
        "      encoded_anime = encoded_anime - lr*grad_anime\n",
        "      #user_change = encoded_user - encoded_user_lag\n",
        "      #anime_change = encoded_anime - encoded_anime_lag\n",
        "      #else:\n",
        "      #  encoded_user_lag = encoded_user\n",
        "      #  encoded_anime_lag = encoded_anime\n",
        "      #  grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "      #  encoded_user = encoded_user - lr*grad_user + B*(user_change)\n",
        "      #  encoded_anime = encoded_anime - lr*grad_anime + B*(anime_change)\n",
        "      #  user_change = encoded_user - encoded_user_lag\n",
        "      #  anime_change = encoded_anime - encoded_anime_lag\n",
        "    #for i in tqdm.tqdm(range(iter)):\n",
        "     #   grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "     #   #encoded_user = encoded_user - lr*grad_user\n",
        "     #   encoded_anime = encoded_anime - lr*grad_anime\n",
        "\n",
        "    return encoded_user, encoded_anime\n",
        "\n",
        "encoded_user = create_embeddings(num_users, 3)\n",
        "encoded_anime = create_embeddings(num_anime, 3)\n",
        "\n",
        "encoded_user, encoded_anime = model(train_data, encoded_user, encoded_anime, 100, 10)\n",
        "\n",
        "train_mse = mse(train_data, encoded_user, encoded_anime)\n",
        "val_mse = mse(valid_data, encoded_user, encoded_anime)\n",
        "print(train_mse, val_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zUdOhzqb6IU",
        "outputId": "bb1cbe08-e563-4696-c5f0-d8f741fe6324"
      },
      "id": "9zUdOhzqb6IU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [05:20<00:00,  3.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33.173610992526655 33.14200916530369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final model based on lecture slide to use on test data set ##  \n",
        "- Decaying Learning rate  \n",
        "- Alternating minimisation  \n",
        "- Gradient descent with momentum  \n",
        "\n"
      ],
      "metadata": {
        "id": "N_wmzj8qEdm7"
      },
      "id": "N_wmzj8qEdm7"
    },
    {
      "cell_type": "code",
      "source": [
        "#rate_getter = lambda x: 1 if x<1 else (10 if x>10 else x) \n",
        "#vfunc = np.vectorize(rate_getter)\n",
        "\n",
        "def mse(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    MSE = np.sum((A - A_approx).power(2))/data.shape[0] \n",
        "    \n",
        "    return MSE\n",
        "\n",
        "def gradient(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    \n",
        "    grad_user = (-2/data.shape[0])*((A - A_approx)*encoded_anime) \n",
        "    grad_anime = (-2/data.shape[0])*((A - A_approx).T*encoded_user)   \n",
        "    return grad_user, grad_anime\n",
        "\n",
        "def create_embeddings(n, K):\n",
        "    \"\"\"\n",
        "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
        "    n: number of items/users\n",
        "    K: number of factors in the embedding \n",
        "    \"\"\"\n",
        "    return 11*np.random.random((n, K)) / K\n",
        "\n",
        "# Gradient descent with momentum\n",
        "def model_momen(data, encoded_user, encoded_anime, iter, lr):\n",
        "    B = 0.9\n",
        "    for i in tqdm.tqdm(range(iter)):\n",
        "      if (i == 0):\n",
        "        encoded_user_lag = encoded_user\n",
        "        encoded_anime_lag = encoded_anime\n",
        "        grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "        encoded_user = encoded_user - lr*grad_user\n",
        "        encoded_anime = encoded_anime - lr*grad_anime\n",
        "        user_change = encoded_user - encoded_user_lag\n",
        "        anime_change = encoded_anime - encoded_anime_lag\n",
        "      else:\n",
        "        encoded_user_lag = encoded_user\n",
        "        encoded_anime_lag = encoded_anime\n",
        "        grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "        encoded_user = encoded_user - lr*grad_user + B*(user_change)\n",
        "        encoded_anime = encoded_anime - lr*grad_anime + B*(anime_change)\n",
        "        user_change = encoded_user - encoded_user_lag\n",
        "        anime_change = encoded_anime - encoded_anime_lag\n",
        "    \n",
        "    return encoded_user, encoded_anime\n",
        "\n",
        "encoded_user = create_embeddings(num_users, 3)\n",
        "encoded_anime = create_embeddings(num_anime, 3)\n",
        "\n",
        "encoded_user, encoded_anime = model_momen(train_data, encoded_user, encoded_anime, 100, 10)\n",
        "\n",
        "#train_mse = mse(train_data, encoded_user, encoded_anime)\n",
        "#val_mse = mse(valid_data, encoded_user, encoded_anime)\n",
        "\n",
        "test = test_data.reset_index()[['user_id', 'anime_id', 'rating']]\n",
        "test_data = encode_new_data(test, user_ids, anime_ids)\n",
        "test_mse = mse(test_data,encoded_user,encoded_anime)"
      ],
      "metadata": {
        "id": "fBZqkf-aEc5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cf8bfb-f81d-412f-fb29-92cb2411b0ef"
      },
      "id": "fBZqkf-aEc5f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [02:12<00:00,  1.32s/it]\n",
            "<ipython-input-19-8b7bf19e6c1b>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_data['anime_id'] =  np.array([anime_ids[x] for x in valid_data['anime_id']])\n",
            "<ipython-input-19-8b7bf19e6c1b>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_data['user_id'] = np.array([user_ids[x] for x in valid_data['user_id']])\n",
            "<ipython-input-14-fd2868d4a209>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['prediction'] = np.sum(np.multiply(encoded_anime[data['anime_id']], encoded_user[data['user_id']]), axis = 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_mse\n",
        "#train_mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPPzNP9Y2Obn",
        "outputId": "c4741c40-2c5a-4914-e46b-15bf2a7d4d5c"
      },
      "id": "wPPzNP9Y2Obn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.889217788253696"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rate_getter = lambda x: 1 if x<1 else (10 if x>10 else x) \n",
        "#vfunc = np.vectorize(rate_getter)\n",
        "\n",
        "def mse(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    MSE = np.sum((A - A_approx).power(2))/data.shape[0] \n",
        "    \n",
        "    return MSE\n",
        "\n",
        "def gradient(data, encoded_user, encoded_anime):\n",
        "    A = sparse_matrix_init(data, encoded_user.shape[0], encoded_anime.shape[0], 'rating')\n",
        "    A_approx = sparse_matrix_init(predict(data, encoded_user, encoded_anime), encoded_user.shape[0], encoded_anime.shape[0], 'prediction')\n",
        "    \n",
        "    grad_user = (-2/data.shape[0])*((A - A_approx)*encoded_anime) \n",
        "    grad_anime = (-2/data.shape[0])*((A - A_approx).T*encoded_user)   \n",
        "    return grad_user, grad_anime\n",
        "\n",
        "def create_embeddings(n, K):\n",
        "    \"\"\"\n",
        "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
        "    n: number of items/users\n",
        "    K: number of factors in the embedding \n",
        "    \"\"\"\n",
        "    return 11*np.random.random((n, K)) / K\n",
        "\n",
        "# Gradient descent with alternate min\n",
        "def model_alt(data, encoded_user, encoded_anime, iter, lr):\n",
        "    for i in tqdm.tqdm(range(iter)):\n",
        "      grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "      encoded_anime = encoded_anime - lr*grad_anime  \n",
        "    for i in tqdm.tqdm(range(iter)):\n",
        "      grad_user, grad_anime = gradient(data, encoded_user, encoded_anime)\n",
        "      encoded_user = encoded_user - lr*grad_user    \n",
        "    return encoded_user, encoded_anime\n",
        "\n",
        "encoded_user = create_embeddings(num_users, 3)\n",
        "encoded_anime = create_embeddings(num_anime, 3)\n",
        "\n",
        "encoded_user, encoded_anime = model_momen(train_data, encoded_user, encoded_anime, 100, 10)\n",
        "\n",
        "#train_mse = mse(train_data, encoded_user, encoded_anime)\n",
        "#val_mse = mse(valid_data, encoded_user, encoded_anime)\n",
        "\n",
        "test = test_data.reset_index()[['user_id', 'anime_id', 'rating']]\n",
        "test_data = encode_new_data(test, user_ids, anime_ids)\n",
        "test_mse = mse(test_data,encoded_user,encoded_anime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPPSKapj5bP8",
        "outputId": "c3dd1818-ddc4-4f06-9b5a-7619fb489873"
      },
      "id": "bPPSKapj5bP8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [02:12<00:00,  1.33s/it]\n",
            "<ipython-input-19-8b7bf19e6c1b>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_data['anime_id'] =  np.array([anime_ids[x] for x in valid_data['anime_id']])\n",
            "<ipython-input-19-8b7bf19e6c1b>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_data['user_id'] = np.array([user_ids[x] for x in valid_data['user_id']])\n",
            "<ipython-input-14-fd2868d4a209>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['prediction'] = np.sum(np.multiply(encoded_anime[data['anime_id']], encoded_user[data['user_id']]), axis = 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_mse\n",
        "test_mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOi-Lalt54-S",
        "outputId": "54eb952b-a995-4e62-dda7-d667312bf36a"
      },
      "id": "LOi-Lalt54-S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.089157280335384"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}